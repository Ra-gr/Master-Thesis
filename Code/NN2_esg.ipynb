{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae2eb46",
   "metadata": {},
   "source": [
    "# Neural Network with 2 hidden layers\n",
    "\n",
    "### Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88d52c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\1491999960.py:22: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the Random Seed\n",
    "seed_value= 2022\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "import numpy  as np\n",
    "import pandas  as pd\n",
    "import datetime\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.formula.api as smf\n",
    "import tensorflow as tf\n",
    "from keras.models     import Sequential, load_model\n",
    "from keras.layers     import Activation, Dense, LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks  import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l1\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddebc495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seeds(seed_value=2022):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)\n",
    "reset_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7bdc01",
   "metadata": {},
   "source": [
    "### Load Dataset - include RepRisk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e7787b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>reprisk_id</th>\n",
       "      <th>prc</th>\n",
       "      <th>vol</th>\n",
       "      <th>mve_m</th>\n",
       "      <th>absacc</th>\n",
       "      <th>acc</th>\n",
       "      <th>aeavol</th>\n",
       "      <th>age</th>\n",
       "      <th>agr</th>\n",
       "      <th>...</th>\n",
       "      <th>sic2_73</th>\n",
       "      <th>sic2_75</th>\n",
       "      <th>sic2_78</th>\n",
       "      <th>sic2_79</th>\n",
       "      <th>sic2_80</th>\n",
       "      <th>sic2_81</th>\n",
       "      <th>sic2_82</th>\n",
       "      <th>sic2_83</th>\n",
       "      <th>sic2_87</th>\n",
       "      <th>sic2_99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>YM</th>\n",
       "      <th>permno</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2007</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2007-01</th>\n",
       "      <th>10025</th>\n",
       "      <td>11903</td>\n",
       "      <td>37172</td>\n",
       "      <td>45.320000</td>\n",
       "      <td>8086.0</td>\n",
       "      <td>3.700557e+05</td>\n",
       "      <td>0.698728</td>\n",
       "      <td>-0.745547</td>\n",
       "      <td>-0.646819</td>\n",
       "      <td>0.457506</td>\n",
       "      <td>-0.979644</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10026</th>\n",
       "      <td>12825</td>\n",
       "      <td>12684</td>\n",
       "      <td>39.689999</td>\n",
       "      <td>7613.0</td>\n",
       "      <td>7.653725e+05</td>\n",
       "      <td>0.577608</td>\n",
       "      <td>-0.635623</td>\n",
       "      <td>-0.393384</td>\n",
       "      <td>0.457506</td>\n",
       "      <td>0.118575</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10042</th>\n",
       "      <td>12139</td>\n",
       "      <td>4832</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>26008.0</td>\n",
       "      <td>3.598898e+04</td>\n",
       "      <td>0.990840</td>\n",
       "      <td>-0.989822</td>\n",
       "      <td>-0.894148</td>\n",
       "      <td>0.457506</td>\n",
       "      <td>-0.989822</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10078</th>\n",
       "      <td>12136</td>\n",
       "      <td>1719</td>\n",
       "      <td>6.130000</td>\n",
       "      <td>11333293.0</td>\n",
       "      <td>2.390900e+07</td>\n",
       "      <td>0.654962</td>\n",
       "      <td>-0.711959</td>\n",
       "      <td>-0.128753</td>\n",
       "      <td>0.905344</td>\n",
       "      <td>-0.147074</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10104</th>\n",
       "      <td>12142</td>\n",
       "      <td>4413</td>\n",
       "      <td>16.430000</td>\n",
       "      <td>7234361.0</td>\n",
       "      <td>8.892640e+07</td>\n",
       "      <td>-0.014758</td>\n",
       "      <td>-0.107379</td>\n",
       "      <td>0.780153</td>\n",
       "      <td>0.905344</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021-12</th>\n",
       "      <th>93304</th>\n",
       "      <td>184167</td>\n",
       "      <td>91339</td>\n",
       "      <td>36.750000</td>\n",
       "      <td>183303.0</td>\n",
       "      <td>1.695898e+06</td>\n",
       "      <td>-0.855522</td>\n",
       "      <td>0.706269</td>\n",
       "      <td>-0.871045</td>\n",
       "      <td>-0.500896</td>\n",
       "      <td>0.613134</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93373</th>\n",
       "      <td>184323</td>\n",
       "      <td>74074</td>\n",
       "      <td>3.020000</td>\n",
       "      <td>528712.0</td>\n",
       "      <td>2.065325e+05</td>\n",
       "      <td>-0.213134</td>\n",
       "      <td>0.143881</td>\n",
       "      <td>0.663284</td>\n",
       "      <td>-0.500896</td>\n",
       "      <td>-0.875821</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93374</th>\n",
       "      <td>184899</td>\n",
       "      <td>64442</td>\n",
       "      <td>74.510002</td>\n",
       "      <td>159495.0</td>\n",
       "      <td>8.587073e+06</td>\n",
       "      <td>-0.514030</td>\n",
       "      <td>0.423284</td>\n",
       "      <td>-0.223881</td>\n",
       "      <td>-0.500896</td>\n",
       "      <td>0.328955</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93423</th>\n",
       "      <td>10567</td>\n",
       "      <td>22547</td>\n",
       "      <td>39.490002</td>\n",
       "      <td>254917.0</td>\n",
       "      <td>3.661156e+06</td>\n",
       "      <td>0.242985</td>\n",
       "      <td>-0.303881</td>\n",
       "      <td>0.560597</td>\n",
       "      <td>0.143881</td>\n",
       "      <td>-0.584478</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93436</th>\n",
       "      <td>184996</td>\n",
       "      <td>24952</td>\n",
       "      <td>936.719971</td>\n",
       "      <td>6361641.0</td>\n",
       "      <td>1.092218e+09</td>\n",
       "      <td>0.584478</td>\n",
       "      <td>-0.620299</td>\n",
       "      <td>-0.362388</td>\n",
       "      <td>-0.500896</td>\n",
       "      <td>0.856716</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338288 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      gvkey  reprisk_id         prc         vol         mve_m  \\\n",
       "year YM      permno                                                             \n",
       "2007 2007-01 10025    11903       37172   45.320000      8086.0  3.700557e+05   \n",
       "             10026    12825       12684   39.689999      7613.0  7.653725e+05   \n",
       "             10042    12139        4832    0.720000     26008.0  3.598898e+04   \n",
       "             10078    12136        1719    6.130000  11333293.0  2.390900e+07   \n",
       "             10104    12142        4413   16.430000   7234361.0  8.892640e+07   \n",
       "...                     ...         ...         ...         ...           ...   \n",
       "2021 2021-12 93304   184167       91339   36.750000    183303.0  1.695898e+06   \n",
       "             93373   184323       74074    3.020000    528712.0  2.065325e+05   \n",
       "             93374   184899       64442   74.510002    159495.0  8.587073e+06   \n",
       "             93423    10567       22547   39.490002    254917.0  3.661156e+06   \n",
       "             93436   184996       24952  936.719971   6361641.0  1.092218e+09   \n",
       "\n",
       "                       absacc       acc    aeavol       age       agr  ...  \\\n",
       "year YM      permno                                                    ...   \n",
       "2007 2007-01 10025   0.698728 -0.745547 -0.646819  0.457506 -0.979644  ...   \n",
       "             10026   0.577608 -0.635623 -0.393384  0.457506  0.118575  ...   \n",
       "             10042   0.990840 -0.989822 -0.894148  0.457506 -0.989822  ...   \n",
       "             10078   0.654962 -0.711959 -0.128753  0.905344 -0.147074  ...   \n",
       "             10104  -0.014758 -0.107379  0.780153  0.905344  0.770992  ...   \n",
       "...                       ...       ...       ...       ...       ...  ...   \n",
       "2021 2021-12 93304  -0.855522  0.706269 -0.871045 -0.500896  0.613134  ...   \n",
       "             93373  -0.213134  0.143881  0.663284 -0.500896 -0.875821  ...   \n",
       "             93374  -0.514030  0.423284 -0.223881 -0.500896  0.328955  ...   \n",
       "             93423   0.242985 -0.303881  0.560597  0.143881 -0.584478  ...   \n",
       "             93436   0.584478 -0.620299 -0.362388 -0.500896  0.856716  ...   \n",
       "\n",
       "                     sic2_73  sic2_75  sic2_78  sic2_79  sic2_80  sic2_81  \\\n",
       "year YM      permno                                                         \n",
       "2007 2007-01 10025         0        0        0        0        0        0   \n",
       "             10026         0        0        0        0        0        0   \n",
       "             10042         0        0        0        0        0        0   \n",
       "             10078         0        0        0        0        0        0   \n",
       "             10104         1        0        0        0        0        0   \n",
       "...                      ...      ...      ...      ...      ...      ...   \n",
       "2021 2021-12 93304         0        0        0        0        0        0   \n",
       "             93373         0        0        0        0        0        0   \n",
       "             93374         0        0        0        0        0        0   \n",
       "             93423         0        0        0        1        0        0   \n",
       "             93436         0        0        0        0        0        0   \n",
       "\n",
       "                     sic2_82  sic2_83  sic2_87  sic2_99  \n",
       "year YM      permno                                      \n",
       "2007 2007-01 10025         0        0        0        0  \n",
       "             10026         0        0        0        0  \n",
       "             10042         0        0        0        0  \n",
       "             10078         0        0        0        0  \n",
       "             10104         0        0        0        0  \n",
       "...                      ...      ...      ...      ...  \n",
       "2021 2021-12 93304         0        0        0        0  \n",
       "             93373         0        0        0        0  \n",
       "             93374         0        0        0        0  \n",
       "             93423         0        0        0        0  \n",
       "             93436         0        0        0        0  \n",
       "\n",
       "[338288 rows x 188 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load monthly firm characteristics raw data\n",
    "df = pd.read_parquet('C:/Users/rafae/Documents/HSG/Master Thesis/Data/Final/data07_model_input.parquet')\n",
    "df = df.sort_values(by=['YM', 'permno'])\n",
    "df = df.set_index(['year', 'YM', 'permno'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1483e4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((338288, 180), (338288, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only relevant columns for X and Y (exclude industry & reprisk rating dummy for now)\n",
    "info_vars = ['YM', 'year', 'permno', 'gvkey', 'reprisk_id', 'prc', 'vol', 'mve_m']\n",
    "X_vars = ['absacc', 'acc', 'aeavol', 'age', 'agr', 'baspread', 'beta', 'betasq', 'bm', 'bm_ia', 'cash', 'cashdebt',\n",
    "          'cashpr', 'cfp', 'cfp_ia', 'chatoia', 'chcsho', 'chempia', 'chinv', 'chmom', 'chpmia', 'chtx', 'cinvest',\n",
    "          'convind', 'currat', 'depr', 'divi', 'divo', 'dolvol', 'dy', 'ear', 'egr', 'ep', 'gma', 'grcapx', 'grltnoa',\n",
    "          'herf', 'hire', 'idiovol', 'ill', 'indmom', 'invest', 'lev', 'lgr', 'maxret', 'mom12m', 'mom1m', 'mom36m',\n",
    "          'mom6m', 'ms', 'mve', 'mve_ia', 'nincr', 'operprof', 'orgcap', 'pchcapx_ia', 'pchcurrat', 'pchdepr',\n",
    "          'pchgm_pchsale', 'pchquick', 'pchsale_pchinvt', 'pchsale_pchrect', 'pchsale_pchxsga', 'pchsaleinv', 'pctacc',\n",
    "          'pricedelay', 'ps', 'quick', 'rd', 'rd_mve', 'rd_sale', 'realestate', 'retvol', 'roaq', 'roavol', 'roeq',\n",
    "          'roic', 'rsup', 'salecash', 'saleinv', 'salerec', 'secured', 'securedind', 'sgr', 'sin', 'sp', 'std_dolvol',\n",
    "          'std_turn', 'stdacc', 'stdcf', 'tang', 'tb', 'turn', 'zerotrade']\n",
    "sic2_vars = [col for col in df if col.startswith('sic2')]\n",
    "reprisk_vars = ['country_sector_average', 'country_sector_average_01', 'current_rri', 'current_rri_01',\n",
    "                'peak_rri', 'peak_rri_01', 'trend_rri', 'trend_rri_01']\n",
    "reprisk_rating_vars = [col for col in df if col.startswith('reprisk_rating')]\n",
    "Y_vars = ['ret', 'ret_wins', 'ret_ex']\n",
    "\n",
    "# X\n",
    "X = df[X_vars + sic2_vars + reprisk_vars + reprisk_rating_vars]\n",
    "\n",
    "# Y\n",
    "Y = df[['ret_ex']]\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685978d6",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization: 4-Fold CV (12y/4 = 3y) and 3y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adec0132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training (12y - 80%) and Test set (3y - 20%)\n",
    "X_trai = X.loc['2007':'2018']\n",
    "Y_trai = Y.loc['2007':'2018']\n",
    "\n",
    "X_test = X.loc['2019':'2021']\n",
    "Y_test = Y.loc['2019':'2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f017dc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2007', '2008', '2009'] ['2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018']\n",
      "['2010', '2011', '2012'] ['2007', '2008', '2009', '2013', '2014', '2015', '2016', '2017', '2018']\n",
      "['2013', '2014', '2015'] ['2007', '2008', '2009', '2010', '2011', '2012', '2016', '2017', '2018']\n",
      "['2016', '2017', '2018'] ['2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015']\n"
     ]
    }
   ],
   "source": [
    "# 4-Fold cross validation (9y training and 3y validation)\n",
    "K_FOLDs = 4\n",
    "YEARS = list(X_trai.index.unique(level='year').astype('str')) \n",
    "TOT = len(YEARS)\n",
    "TRA = int(TOT* (K_FOLDs-1) / K_FOLDs)\n",
    "OFF = TOT - TRA\n",
    "\n",
    "for FOLD in range(K_FOLDs):\n",
    "    VALI = YEARS[(FOLD*OFF):((FOLD+1)*OFF)]\n",
    "    TRAI = [x for x in YEARS if x not in VALI]\n",
    "    print(VALI, TRAI)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "637c2ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'NN2_esg'\n",
    "\n",
    "def create_NN2(l_rate=0.01, l1_pen=0.0001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32,\n",
    "                    activation='relu',\n",
    "                    input_dim=X_trai.shape[1],\n",
    "                    kernel_regularizer=l1(l1_pen)))\n",
    "    model.add(Dense(16,\n",
    "                    activation='relu',\n",
    "                    kernel_regularizer=l1(l1_pen)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=l_rate))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca9059e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• 0 : Epoch 8: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 7: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 1 : Epoch 8: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 6: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 2 : Epoch 8: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 7: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 7: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 7: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 3 : Epoch 8: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 7: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 4 : Epoch 9: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 8: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 5 : Epoch 10: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 7: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 8: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 8: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 6 : Epoch 8: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 7: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 7: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 7 : Epoch 8: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 8: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 8: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 8 : Epoch 12: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 14: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 9 : Epoch 8: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 8: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 8: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 10 : Epoch 9: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 11 : Epoch 9: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 8: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 12 : Epoch 9: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 8: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 8: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 13 : Epoch 9: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2193/2193 [==============================] - 6s 3ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 14 : Epoch 9: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 15 : Epoch 8: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 8: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 8: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 16 : Epoch 10: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 17 : Epoch 10: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 18 : Epoch 14: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 8: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 19 : Epoch 10: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 11: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 20 : Epoch 27: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 30: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 27: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 21 : Epoch 12: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 22 : Epoch 17: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 16: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 17: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 23 : Epoch 21: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 24 : Epoch 22: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 24: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 25 : Epoch 20: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 17: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 26 : Epoch 26: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 26: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 27 : Epoch 25: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 27: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 25: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 28 : Epoch 18: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 17: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 29 : Epoch 27: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 28: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 26: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 29: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 30 : Epoch 13: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 14: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 31 : Epoch 13: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 32 : Epoch 12: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 11: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 33 : Epoch 14: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 16: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 16: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 34 : Epoch 15: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 16: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 35 : Epoch 15: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 16: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 36 : Epoch 16: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 14: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 37 : Epoch 13: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 14: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 17: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 38 : Epoch 14: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 39 : Epoch 19: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 17: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 16: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 16: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 40 : Epoch 18: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 41 : Epoch 11: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 11: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 42 : Epoch 13: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 43 : Epoch 18: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 34: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 44 : Epoch 19: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 24: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 45 : Epoch 22: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 17: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 46 : Epoch 16: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 14: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 17: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 47 : Epoch 26: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 48 : Epoch 14: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 16: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 14: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 49 : Epoch 22: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 24: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 50 : Epoch 46: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 50: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 49: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 49: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 51 : Epoch 34: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 32: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 30: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 25: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 52 : Epoch 36: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 34: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 39: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 40: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 53 : Epoch 42: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 39: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 46: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 41: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 54 : Epoch 48: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 45: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 54: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 46: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 55 : Epoch 42: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 41: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 40: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 39: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 56 : Epoch 40: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 37: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 53: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 39: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 57 : Epoch 48: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 48: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 45: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 47: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 58 : Epoch 32: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 34: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 40: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 35: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 59 : Epoch 56: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 48: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 60: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 60: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 60 : Epoch 18: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 61 : Epoch 13: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 14: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 62 : Epoch 21: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 14: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 63 : Epoch 18: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 24: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 64 : Epoch 17: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 17: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 65 : Epoch 22: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 66 : Epoch 16: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 16: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 67 : Epoch 17: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 26: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 24: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 68 : Epoch 14: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 11: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 69 : Epoch 17: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 70 : Epoch 29: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 26: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 71 : Epoch 13: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 72 : Epoch 22: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 24: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 73 : Epoch 19: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 34: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 74 : Epoch 26: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 29: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 27: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 34: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 75 : Epoch 22: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 76 : Epoch 30: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 77 : Epoch 31: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 26: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 30: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 78 : Epoch 17: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 79 : Epoch 37: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 36: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 31: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 29: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 80 : Epoch 60: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 45: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 53: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 60: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 81 : Epoch 34: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 34: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 41: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 33: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 82 : Epoch 36: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 44: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 45: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 47: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 83 : Epoch 57: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 47: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 52: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 51: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 84 : Epoch 57: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 45: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 57: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 52: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 85 : Epoch 42: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 41: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 58: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 45: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 86 : Epoch 59: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 48: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 47: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 52: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 87 : Epoch 66: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 58: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 56: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 61: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 88 : Epoch 37: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 45: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 40: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 38: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 89 : Epoch 65: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 62: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 68: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 65: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 90 : Epoch 21: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 17: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 24: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 36: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 91 : Epoch 22: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 32: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 92 : Epoch 26: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 93 : Epoch 33: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 28: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 29: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 31: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 94 : Epoch 26: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 16: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 95 : Epoch 22: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 96 : Epoch 28: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 16: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 97 : Epoch 31: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 26: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 36: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 25: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 98 : Epoch 15: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 14: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 17: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 99 : Epoch 28: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 55s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 30: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 32: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 100 : Epoch 31: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 52s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 38: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 101 : Epoch 23: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 56s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 26: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 32: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 102 : Epoch 27: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 57s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 29: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 28: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 103 : Epoch 27: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 53s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 33: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 33: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 104 : Epoch 26: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 30: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 31: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 105 : Epoch 28: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 54s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 5s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 28: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 29: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 106 : Epoch 30: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 53s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 27: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 34: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 107 : Epoch 29: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 57s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 37: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 25: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 108 : Epoch 26: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 54s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 109 : Epoch 37: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 53s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 35: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 40: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 110 : Epoch 60: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 52s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 38: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 49: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 111 : Epoch 44: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 55s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 5s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 32: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 36: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 112 : Epoch 47: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 5s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 37: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 33: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 113 : Epoch 65: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 53s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 42: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 41: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 114 : Epoch 63: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 53s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 41: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 36: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 115 : Epoch 45: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 53s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 38: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 43: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 116 : Epoch 59: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 53s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 37: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 55: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 117 : Epoch 66: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 45: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 51: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 118 : Epoch 48: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 55s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 37: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 28: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 119 : Epoch 65: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 56s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 5s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_2760\\2779473123.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 48: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 48: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter optimization\n",
    "Y_val_preds = Y_trai.copy()\n",
    "Y_test_preds = Y_test.copy()\n",
    "results = []\n",
    "\n",
    "earlyStopping  = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
    "\n",
    "model_ix = 0\n",
    "for l1_pen in [0.001, 0.0001, 0.00005, 0.00001]:\n",
    "        for l_rate in [0.01, 0.005, 0.001]:\n",
    "            for ensemble in list(range(0,10)):\n",
    "                print(\"•\", model_ix, ':',  end=' ')\n",
    "                    \n",
    "                for FOLD in range(K_FOLDs):\n",
    "                    VALI = YEARS[(FOLD*OFF):((FOLD+1)*OFF)]\n",
    "                    TRAI = [x for x in YEARS if x not in VALI]\n",
    "                        \n",
    "                    mcp_save = ModelCheckpoint(\n",
    "                        '%s/%s_%d_%d.h5'%(model_name, model_name, model_ix, FOLD),\n",
    "                        save_best_only=True, monitor='val_loss', mode='min', save_weights_only=True\n",
    "                    )\n",
    "\n",
    "                    reset_seeds(ensemble*10000)\n",
    "                        \n",
    "                    NN_model = create_NN2(l_rate, l1_pen)\n",
    "                        \n",
    "                    history = NN_model.fit(\n",
    "                        X_trai.loc[TRAI], Y_trai.loc[TRAI],\n",
    "                        validation_data=(X_trai.loc[VALI], Y_trai.loc[VALI]),\n",
    "                        epochs=200, verbose=0, shuffle=True, batch_size=2000,\n",
    "                        callbacks=[earlyStopping, mcp_save]\n",
    "                    )\n",
    "                    tra_loss = np.min(history.history['loss'])\n",
    "                    val_loss = np.min(history.history['val_loss'])\n",
    "\n",
    "                    results.append({\n",
    "                        'model_ix' :model_ix,\n",
    "                        'l_rate'   :l_rate,\n",
    "                        'l1_pen'   :l1_pen,\n",
    "                        'fold'     :FOLD,\n",
    "                        'tra_loss' :tra_loss,\n",
    "                        'val_loss' :val_loss\n",
    "                    })\n",
    "                    \n",
    "                    # Calculate validation predictions\n",
    "                    best_model = create_NN2(l_rate, l1_pen)\n",
    "                    best_model.load_weights(r'%s/%s_%d_%d.h5'%(model_name, model_name, model_ix, FOLD));\n",
    "                    Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n",
    "                    \n",
    "                    # Calculate predictions for test data, if FOLD = 0\n",
    "                    if FOLD==0:\n",
    "                        Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n",
    "\n",
    "                model_ix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ee0ffe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ret_ex</th>\n",
       "      <th>NN2_esg_0</th>\n",
       "      <th>NN2_esg_1</th>\n",
       "      <th>NN2_esg_2</th>\n",
       "      <th>NN2_esg_3</th>\n",
       "      <th>NN2_esg_4</th>\n",
       "      <th>NN2_esg_5</th>\n",
       "      <th>NN2_esg_6</th>\n",
       "      <th>NN2_esg_7</th>\n",
       "      <th>NN2_esg_8</th>\n",
       "      <th>...</th>\n",
       "      <th>NN2_esg_110</th>\n",
       "      <th>NN2_esg_111</th>\n",
       "      <th>NN2_esg_112</th>\n",
       "      <th>NN2_esg_113</th>\n",
       "      <th>NN2_esg_114</th>\n",
       "      <th>NN2_esg_115</th>\n",
       "      <th>NN2_esg_116</th>\n",
       "      <th>NN2_esg_117</th>\n",
       "      <th>NN2_esg_118</th>\n",
       "      <th>NN2_esg_119</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>YM</th>\n",
       "      <th>permno</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2007</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2007-01</th>\n",
       "      <th>10025</th>\n",
       "      <td>-0.031894</td>\n",
       "      <td>0.011666</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>0.009020</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.008940</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016098</td>\n",
       "      <td>0.017669</td>\n",
       "      <td>0.009631</td>\n",
       "      <td>0.027925</td>\n",
       "      <td>0.021682</td>\n",
       "      <td>0.022546</td>\n",
       "      <td>0.019406</td>\n",
       "      <td>0.018377</td>\n",
       "      <td>0.011536</td>\n",
       "      <td>0.011978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10026</th>\n",
       "      <td>-0.042317</td>\n",
       "      <td>0.011666</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.008937</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008942</td>\n",
       "      <td>0.010883</td>\n",
       "      <td>0.009293</td>\n",
       "      <td>0.013151</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.009321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10042</th>\n",
       "      <td>-0.125751</td>\n",
       "      <td>0.011666</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>0.009020</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.008940</td>\n",
       "      <td>0.005086</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025225</td>\n",
       "      <td>-0.035010</td>\n",
       "      <td>-0.022063</td>\n",
       "      <td>-0.003215</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>-0.011502</td>\n",
       "      <td>-0.019681</td>\n",
       "      <td>-0.019573</td>\n",
       "      <td>-0.017476</td>\n",
       "      <td>-0.024196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10078</th>\n",
       "      <td>-0.080607</td>\n",
       "      <td>0.011666</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>0.009015</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.008938</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010010</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>0.013151</td>\n",
       "      <td>0.008577</td>\n",
       "      <td>0.012816</td>\n",
       "      <td>0.009921</td>\n",
       "      <td>0.013220</td>\n",
       "      <td>0.012152</td>\n",
       "      <td>0.009503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10104</th>\n",
       "      <td>-0.046341</td>\n",
       "      <td>0.011666</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.008940</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015029</td>\n",
       "      <td>0.013234</td>\n",
       "      <td>0.009847</td>\n",
       "      <td>0.013151</td>\n",
       "      <td>0.016532</td>\n",
       "      <td>0.012422</td>\n",
       "      <td>0.015742</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.012424</td>\n",
       "      <td>0.011053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2018</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2018-12</th>\n",
       "      <th>93420</th>\n",
       "      <td>0.086508</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.008348</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.006922</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.006231</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.010730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006488</td>\n",
       "      <td>0.017752</td>\n",
       "      <td>-0.010887</td>\n",
       "      <td>0.014370</td>\n",
       "      <td>-0.019347</td>\n",
       "      <td>0.012553</td>\n",
       "      <td>0.004488</td>\n",
       "      <td>0.003901</td>\n",
       "      <td>-0.028114</td>\n",
       "      <td>-0.022514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93422</th>\n",
       "      <td>0.466817</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>0.004536</td>\n",
       "      <td>0.008348</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.006922</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.006231</td>\n",
       "      <td>0.006967</td>\n",
       "      <td>0.010730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019117</td>\n",
       "      <td>0.007956</td>\n",
       "      <td>0.016913</td>\n",
       "      <td>-0.012194</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>-0.001040</td>\n",
       "      <td>-0.018191</td>\n",
       "      <td>-0.004372</td>\n",
       "      <td>-0.020061</td>\n",
       "      <td>-0.026303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93423</th>\n",
       "      <td>0.105036</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>0.008348</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.006922</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.006232</td>\n",
       "      <td>0.006965</td>\n",
       "      <td>0.010730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>-0.002086</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.010569</td>\n",
       "      <td>-0.006907</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>0.017746</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.003485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93429</th>\n",
       "      <td>-0.048712</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.008348</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.006922</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.006236</td>\n",
       "      <td>0.006959</td>\n",
       "      <td>0.010730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.005963</td>\n",
       "      <td>0.009815</td>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.011636</td>\n",
       "      <td>0.005975</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.011681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93436</th>\n",
       "      <td>-0.079564</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.008348</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.006922</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.006235</td>\n",
       "      <td>0.006963</td>\n",
       "      <td>0.010730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>-0.017288</td>\n",
       "      <td>0.004422</td>\n",
       "      <td>-0.013494</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>-0.011379</td>\n",
       "      <td>0.010968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276564 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ret_ex  NN2_esg_0  NN2_esg_1  NN2_esg_2  NN2_esg_3  \\\n",
       "year YM      permno                                                         \n",
       "2007 2007-01 10025  -0.031894   0.011666   0.006063   0.011684   0.007911   \n",
       "             10026  -0.042317   0.011666   0.006063   0.011684   0.007911   \n",
       "             10042  -0.125751   0.011666   0.006066   0.011684   0.007911   \n",
       "             10078  -0.080607   0.011666   0.006059   0.011684   0.007911   \n",
       "             10104  -0.046341   0.011666   0.006061   0.011684   0.007911   \n",
       "...                       ...        ...        ...        ...        ...   \n",
       "2018 2018-12 93420   0.086508   0.005554   0.004537   0.008348   0.004325   \n",
       "             93422   0.466817   0.005554   0.004536   0.008348   0.004325   \n",
       "             93423   0.105036   0.005554   0.004540   0.008348   0.004325   \n",
       "             93429  -0.048712   0.005554   0.004537   0.008348   0.004325   \n",
       "             93436  -0.079564   0.005554   0.004537   0.008348   0.004325   \n",
       "\n",
       "                     NN2_esg_4  NN2_esg_5  NN2_esg_6  NN2_esg_7  NN2_esg_8  \\\n",
       "year YM      permno                                                          \n",
       "2007 2007-01 10025    0.006436   0.009020   0.008703   0.008940   0.005088   \n",
       "             10026    0.006436   0.009023   0.008703   0.008937   0.005087   \n",
       "             10042    0.006436   0.009020   0.008703   0.008940   0.005086   \n",
       "             10078    0.006436   0.009015   0.008703   0.008938   0.005087   \n",
       "             10104    0.006436   0.009013   0.008703   0.008940   0.005088   \n",
       "...                        ...        ...        ...        ...        ...   \n",
       "2018 2018-12 93420    0.006922   0.006752   0.006231   0.006969   0.010730   \n",
       "             93422    0.006922   0.006752   0.006231   0.006967   0.010730   \n",
       "             93423    0.006922   0.006752   0.006232   0.006965   0.010730   \n",
       "             93429    0.006922   0.006752   0.006236   0.006959   0.010730   \n",
       "             93436    0.006922   0.006752   0.006235   0.006963   0.010730   \n",
       "\n",
       "                     ...  NN2_esg_110  NN2_esg_111  NN2_esg_112  NN2_esg_113  \\\n",
       "year YM      permno  ...                                                       \n",
       "2007 2007-01 10025   ...     0.016098     0.017669     0.009631     0.027925   \n",
       "             10026   ...     0.008942     0.010883     0.009293     0.013151   \n",
       "             10042   ...    -0.025225    -0.035010    -0.022063    -0.003215   \n",
       "             10078   ...     0.010010     0.007480     0.006376     0.013151   \n",
       "             10104   ...     0.015029     0.013234     0.009847     0.013151   \n",
       "...                  ...          ...          ...          ...          ...   \n",
       "2018 2018-12 93420   ...    -0.006488     0.017752    -0.010887     0.014370   \n",
       "             93422   ...    -0.019117     0.007956     0.016913    -0.012194   \n",
       "             93423   ...     0.010453    -0.002086     0.002797     0.010569   \n",
       "             93429   ...     0.010700     0.003399     0.005963     0.009815   \n",
       "             93436   ...     0.010700    -0.001668     0.005357     0.007096   \n",
       "\n",
       "                     NN2_esg_114  NN2_esg_115  NN2_esg_116  NN2_esg_117  \\\n",
       "year YM      permno                                                       \n",
       "2007 2007-01 10025      0.021682     0.022546     0.019406     0.018377   \n",
       "             10026      0.003620     0.010453     0.004467     0.007610   \n",
       "             10042     -0.038086    -0.011502    -0.019681    -0.019573   \n",
       "             10078      0.008577     0.012816     0.009921     0.013220   \n",
       "             10104      0.016532     0.012422     0.015742     0.010870   \n",
       "...                          ...          ...          ...          ...   \n",
       "2018 2018-12 93420     -0.019347     0.012553     0.004488     0.003901   \n",
       "             93422      0.000309    -0.001040    -0.018191    -0.004372   \n",
       "             93423     -0.006907     0.002783     0.017746     0.006538   \n",
       "             93429      0.010585     0.000793     0.011636     0.005975   \n",
       "             93436     -0.017288     0.004422    -0.013494    -0.007546   \n",
       "\n",
       "                     NN2_esg_118  NN2_esg_119  \n",
       "year YM      permno                            \n",
       "2007 2007-01 10025      0.011536     0.011978  \n",
       "             10026      0.004558     0.009321  \n",
       "             10042     -0.017476    -0.024196  \n",
       "             10078      0.012152     0.009503  \n",
       "             10104      0.012424     0.011053  \n",
       "...                          ...          ...  \n",
       "2018 2018-12 93420     -0.028114    -0.022514  \n",
       "             93422     -0.020061    -0.026303  \n",
       "             93423      0.006881     0.003485  \n",
       "             93429      0.006187     0.011681  \n",
       "             93436     -0.011379     0.010968  \n",
       "\n",
       "[276564 rows x 121 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Y_val_preds\n",
    "Y_val_preds.to_csv(r'%s/%s_val_preds.csv'%(model_name, model_name))\n",
    "Y_val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1418be9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ret_ex</th>\n",
       "      <th>NN2_esg_0</th>\n",
       "      <th>NN2_esg_1</th>\n",
       "      <th>NN2_esg_2</th>\n",
       "      <th>NN2_esg_3</th>\n",
       "      <th>NN2_esg_4</th>\n",
       "      <th>NN2_esg_5</th>\n",
       "      <th>NN2_esg_6</th>\n",
       "      <th>NN2_esg_7</th>\n",
       "      <th>NN2_esg_8</th>\n",
       "      <th>...</th>\n",
       "      <th>NN2_esg_110</th>\n",
       "      <th>NN2_esg_111</th>\n",
       "      <th>NN2_esg_112</th>\n",
       "      <th>NN2_esg_113</th>\n",
       "      <th>NN2_esg_114</th>\n",
       "      <th>NN2_esg_115</th>\n",
       "      <th>NN2_esg_116</th>\n",
       "      <th>NN2_esg_117</th>\n",
       "      <th>NN2_esg_118</th>\n",
       "      <th>NN2_esg_119</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>YM</th>\n",
       "      <th>permno</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2019</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2019-01</th>\n",
       "      <th>10026</th>\n",
       "      <td>0.004225</td>\n",
       "      <td>0.011666</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.008936</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008942</td>\n",
       "      <td>0.010098</td>\n",
       "      <td>0.007950</td>\n",
       "      <td>0.013151</td>\n",
       "      <td>0.009669</td>\n",
       "      <td>0.010902</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.009348</td>\n",
       "      <td>0.008736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10104</th>\n",
       "      <td>0.036026</td>\n",
       "      <td>0.011666</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>0.009020</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.008941</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012335</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.012755</td>\n",
       "      <td>-0.001677</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.004182</td>\n",
       "      <td>-0.005010</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>0.008393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10107</th>\n",
       "      <td>0.075381</td>\n",
       "      <td>0.011666</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>0.009015</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.008941</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.007897</td>\n",
       "      <td>0.008832</td>\n",
       "      <td>0.013151</td>\n",
       "      <td>0.009956</td>\n",
       "      <td>0.012070</td>\n",
       "      <td>0.006342</td>\n",
       "      <td>0.007986</td>\n",
       "      <td>0.009129</td>\n",
       "      <td>0.012721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10138</th>\n",
       "      <td>0.072777</td>\n",
       "      <td>0.011666</td>\n",
       "      <td>0.006062</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>0.009022</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.008936</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011258</td>\n",
       "      <td>0.009879</td>\n",
       "      <td>0.006535</td>\n",
       "      <td>0.013151</td>\n",
       "      <td>0.011292</td>\n",
       "      <td>0.007917</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.010110</td>\n",
       "      <td>0.009740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10145</th>\n",
       "      <td>0.076596</td>\n",
       "      <td>0.011666</td>\n",
       "      <td>0.006062</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>0.009017</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.008937</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008942</td>\n",
       "      <td>0.009039</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.009496</td>\n",
       "      <td>0.009610</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>0.010111</td>\n",
       "      <td>0.008684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021-12</th>\n",
       "      <th>93304</th>\n",
       "      <td>-0.096386</td>\n",
       "      <td>0.011666</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.008937</td>\n",
       "      <td>0.005089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0.007371</td>\n",
       "      <td>0.010392</td>\n",
       "      <td>0.017144</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.006460</td>\n",
       "      <td>0.009863</td>\n",
       "      <td>0.009818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93373</th>\n",
       "      <td>-0.019481</td>\n",
       "      <td>0.011666</td>\n",
       "      <td>0.006058</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.008931</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014488</td>\n",
       "      <td>-0.021858</td>\n",
       "      <td>-0.010336</td>\n",
       "      <td>-0.013971</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>-0.045553</td>\n",
       "      <td>-0.032068</td>\n",
       "      <td>-0.036441</td>\n",
       "      <td>-0.024536</td>\n",
       "      <td>-0.034007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93374</th>\n",
       "      <td>-0.047552</td>\n",
       "      <td>0.011666</td>\n",
       "      <td>0.006062</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>0.009020</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.008938</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014683</td>\n",
       "      <td>0.011641</td>\n",
       "      <td>0.007024</td>\n",
       "      <td>0.013151</td>\n",
       "      <td>0.009972</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>0.007720</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>0.010112</td>\n",
       "      <td>0.008247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93423</th>\n",
       "      <td>-0.072569</td>\n",
       "      <td>0.011666</td>\n",
       "      <td>0.006060</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>0.009027</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.008935</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013887</td>\n",
       "      <td>-0.000960</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.013151</td>\n",
       "      <td>0.014171</td>\n",
       "      <td>0.013881</td>\n",
       "      <td>0.013902</td>\n",
       "      <td>0.012448</td>\n",
       "      <td>0.016196</td>\n",
       "      <td>0.012207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93436</th>\n",
       "      <td>-0.113609</td>\n",
       "      <td>0.011666</td>\n",
       "      <td>0.006064</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>0.009011</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.008939</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004580</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>0.010630</td>\n",
       "      <td>0.008646</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>-0.007373</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>-0.003046</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.008130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61724 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ret_ex  NN2_esg_0  NN2_esg_1  NN2_esg_2  NN2_esg_3  \\\n",
       "year YM      permno                                                         \n",
       "2019 2019-01 10026   0.004225   0.011666   0.006063   0.011684   0.007911   \n",
       "             10104   0.036026   0.011666   0.006063   0.011684   0.007911   \n",
       "             10107   0.075381   0.011666   0.006063   0.011684   0.007911   \n",
       "             10138   0.072777   0.011666   0.006062   0.011684   0.007911   \n",
       "             10145   0.076596   0.011666   0.006062   0.011684   0.007911   \n",
       "...                       ...        ...        ...        ...        ...   \n",
       "2021 2021-12 93304  -0.096386   0.011666   0.006063   0.011684   0.007911   \n",
       "             93373  -0.019481   0.011666   0.006058   0.011684   0.007911   \n",
       "             93374  -0.047552   0.011666   0.006062   0.011684   0.007911   \n",
       "             93423  -0.072569   0.011666   0.006060   0.011684   0.007911   \n",
       "             93436  -0.113609   0.011666   0.006064   0.011684   0.007911   \n",
       "\n",
       "                     NN2_esg_4  NN2_esg_5  NN2_esg_6  NN2_esg_7  NN2_esg_8  \\\n",
       "year YM      permno                                                          \n",
       "2019 2019-01 10026    0.006436   0.009024   0.008703   0.008936   0.005088   \n",
       "             10104    0.006436   0.009020   0.008703   0.008941   0.005088   \n",
       "             10107    0.006436   0.009015   0.008703   0.008941   0.005087   \n",
       "             10138    0.006436   0.009022   0.008703   0.008936   0.005088   \n",
       "             10145    0.006436   0.009017   0.008703   0.008937   0.005087   \n",
       "...                        ...        ...        ...        ...        ...   \n",
       "2021 2021-12 93304    0.006436   0.009023   0.008703   0.008937   0.005089   \n",
       "             93373    0.006436   0.009024   0.008703   0.008931   0.005087   \n",
       "             93374    0.006436   0.009020   0.008703   0.008938   0.005087   \n",
       "             93423    0.006436   0.009027   0.008703   0.008935   0.005087   \n",
       "             93436    0.006436   0.009011   0.008703   0.008939   0.005087   \n",
       "\n",
       "                     ...  NN2_esg_110  NN2_esg_111  NN2_esg_112  NN2_esg_113  \\\n",
       "year YM      permno  ...                                                       \n",
       "2019 2019-01 10026   ...     0.008942     0.010098     0.007950     0.013151   \n",
       "             10104   ...     0.012335     0.010645     0.000891     0.012755   \n",
       "             10107   ...     0.010037     0.007897     0.008832     0.013151   \n",
       "             10138   ...     0.011258     0.009879     0.006535     0.013151   \n",
       "             10145   ...     0.008942     0.009039     0.006635     0.009726   \n",
       "...                  ...          ...          ...          ...          ...   \n",
       "2021 2021-12 93304   ...     0.002992     0.010037     0.007371     0.010392   \n",
       "             93373   ...    -0.014488    -0.021858    -0.010336    -0.013971   \n",
       "             93374   ...     0.014683     0.011641     0.007024     0.013151   \n",
       "             93423   ...     0.013887    -0.000960     0.008000     0.013151   \n",
       "             93436   ...     0.004580     0.004517     0.010630     0.008646   \n",
       "\n",
       "                     NN2_esg_114  NN2_esg_115  NN2_esg_116  NN2_esg_117  \\\n",
       "year YM      permno                                                       \n",
       "2019 2019-01 10026      0.009669     0.010902     0.005462     0.004801   \n",
       "             10104     -0.001677     0.003820     0.004182    -0.005010   \n",
       "             10107      0.009956     0.012070     0.006342     0.007986   \n",
       "             10138      0.011292     0.007917     0.004816     0.006246   \n",
       "             10145      0.009496     0.009610     0.004838     0.005365   \n",
       "...                          ...          ...          ...          ...   \n",
       "2021 2021-12 93304      0.017144     0.004292     0.009497     0.006460   \n",
       "             93373      0.001835    -0.045553    -0.032068    -0.036441   \n",
       "             93374      0.009972     0.005831     0.007720     0.006445   \n",
       "             93423      0.014171     0.013881     0.013902     0.012448   \n",
       "             93436      0.001656    -0.007373     0.001585    -0.003046   \n",
       "\n",
       "                     NN2_esg_118  NN2_esg_119  \n",
       "year YM      permno                            \n",
       "2019 2019-01 10026      0.009348     0.008736  \n",
       "             10104      0.001682     0.008393  \n",
       "             10107      0.009129     0.012721  \n",
       "             10138      0.010110     0.009740  \n",
       "             10145      0.010111     0.008684  \n",
       "...                          ...          ...  \n",
       "2021 2021-12 93304      0.009863     0.009818  \n",
       "             93373     -0.024536    -0.034007  \n",
       "             93374      0.010112     0.008247  \n",
       "             93423      0.016196     0.012207  \n",
       "             93436      0.006918     0.008130  \n",
       "\n",
       "[61724 rows x 121 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Y_test_preds\n",
    "Y_test_preds.to_csv(r'%s/%s_test_preds.csv'%(model_name, model_name))\n",
    "Y_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b90d143c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tra_loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_ix</th>\n",
       "      <th>l_rate</th>\n",
       "      <th>l1_pen</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12.990696</td>\n",
       "      <td>12.953650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12.989840</td>\n",
       "      <td>12.954744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>12.977617</td>\n",
       "      <td>12.955207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12.990455</td>\n",
       "      <td>12.956974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>12.973617</td>\n",
       "      <td>12.958101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12.992280</td>\n",
       "      <td>12.960384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>12.975841</td>\n",
       "      <td>12.961063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <th>0.010</th>\n",
       "      <th>0.00001</th>\n",
       "      <td>12.978927</td>\n",
       "      <td>12.961299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>12.973895</td>\n",
       "      <td>12.965009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12.994028</td>\n",
       "      <td>12.968817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12.995357</td>\n",
       "      <td>12.968882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12.991261</td>\n",
       "      <td>12.969395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>12.976209</td>\n",
       "      <td>12.969893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>12.977160</td>\n",
       "      <td>12.971074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12.995068</td>\n",
       "      <td>12.973854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>12.980067</td>\n",
       "      <td>12.974066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <th>0.005</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>13.014773</td>\n",
       "      <td>12.975291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12.994352</td>\n",
       "      <td>12.977068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>12.980766</td>\n",
       "      <td>12.977186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>12.976731</td>\n",
       "      <td>12.980818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          tra_loss   val_loss\n",
       "model_ix l_rate l1_pen                       \n",
       "54       0.001  0.00010  12.990696  12.953650\n",
       "51       0.001  0.00010  12.989840  12.954744\n",
       "81       0.001  0.00005  12.977617  12.955207\n",
       "59       0.001  0.00010  12.990455  12.956974\n",
       "89       0.001  0.00005  12.973617  12.958101\n",
       "55       0.001  0.00010  12.992280  12.960384\n",
       "85       0.001  0.00005  12.975841  12.961063\n",
       "91       0.010  0.00001  12.978927  12.961299\n",
       "83       0.001  0.00005  12.973895  12.965009\n",
       "52       0.001  0.00010  12.994028  12.968817\n",
       "57       0.001  0.00010  12.995357  12.968882\n",
       "50       0.001  0.00010  12.991261  12.969395\n",
       "87       0.001  0.00005  12.976209  12.969893\n",
       "82       0.001  0.00005  12.977160  12.971074\n",
       "58       0.001  0.00010  12.995068  12.973854\n",
       "86       0.001  0.00005  12.980067  12.974066\n",
       "73       0.005  0.00005  13.014773  12.975291\n",
       "53       0.001  0.00010  12.994352  12.977068\n",
       "84       0.001  0.00005  12.980766  12.977186\n",
       "80       0.001  0.00005  12.976731  12.980818"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Result overview\n",
    "table = pd.DataFrame(results)\n",
    "table = table.groupby(['model_ix', 'l_rate', 'l1_pen']).mean().sort_values('val_loss')\n",
    "table.to_csv(r'%s/%s_results.csv'%(model_name, model_name))\n",
    "\n",
    "np.sqrt(table[['tra_loss', 'val_loss']].head(20)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a323d8c",
   "metadata": {},
   "source": [
    "## Model Selection: Maximize SR on LS-Portfolio on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb3935fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'NN2_esg'\n",
    "\n",
    "# Get predictions\n",
    "val = pd.read_csv(r'%s/%s_val_preds.csv'%(model_name, model_name), index_col=['year', 'YM', 'permno'])\n",
    "test = pd.read_csv(r'%s/%s_test_preds.csv'%(model_name, model_name), index_col=['year', 'YM', 'permno'])\n",
    "\n",
    "# Get overview table\n",
    "table = pd.read_csv(r'%s/%s_results.csv'%(model_name, model_name)).sort_values(['model_ix'])\n",
    "\n",
    "# Extract hyperparameters\n",
    "list_l_rate = list(pd.unique(table['l_rate']))\n",
    "list_l1_pen = list(pd.unique(table['l1_pen']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7c3acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over hyperparameter combinations to get ensemble predictions for each hyperparameter combination\n",
    "val_results = []\n",
    "hyper_comb = 0\n",
    "for l_rate in list_l_rate:\n",
    "    for l1_pen in list_l1_pen:\n",
    "        # Get list of relevant model_ix\n",
    "        list_model_ix = table[(table['l_rate'] == l_rate) & (table['l1_pen'] == l1_pen)]\n",
    "        list_model_ix = list(list_model_ix['model_ix'])\n",
    "        # Get list of column names\n",
    "        list_col_names = []\n",
    "        for ele in list_model_ix:\n",
    "            list_col_names.append('%s_%d'%(model_name, ele))\n",
    "        # Select relevant returns and average predictions\n",
    "        val_ret = val[list_col_names]\n",
    "        val_ret = val_ret.mean(axis=1)\n",
    "        # Append ensemble return prediction to true returns\n",
    "        comb = val[['ret_ex']].copy()\n",
    "        comb['ret_pred'] = val_ret\n",
    "        comb = comb.reset_index()\n",
    "        # Sort the data by predicted returns and divide the data into quintiles\n",
    "        comb['quintile'] = comb.groupby(['YM'])['ret_pred'].transform(lambda x: pd.qcut(x.rank(method='first'), 5, labels=np.arange(1,6)))\n",
    "        # Calculate the mean return for each YM\n",
    "        comb_mean = comb.groupby(['YM', 'quintile']).agg(ret_ex = ('ret_ex', 'mean'))\n",
    "        # Add LS-Strategy\n",
    "        comb_mean = comb_mean[['ret_ex']].unstack().add_prefix('Q')\n",
    "        comb_mean.columns = comb_mean.columns.droplevel(0)\n",
    "        comb_mean.columns.name = None\n",
    "        comb_mean['LS'] = comb_mean['Q5'] - comb_mean['Q1']\n",
    "        # Calculate the average return, standard deviation and Sharpe Ratio (annualized) per Quintile\n",
    "        summary = pd.DataFrame()\n",
    "        summary['mean'] = comb_mean.mean()\n",
    "        summary['std'] = comb_mean.std()\n",
    "        summary['SR'] = summary['mean'] / summary['std'] * np.sqrt(12)\n",
    "        # Append results\n",
    "        val_results.append({\n",
    "            'hyper_comb':hyper_comb,\n",
    "            'l_rate'    :l_rate,\n",
    "            'l1_pen'    :l1_pen,\n",
    "            'SR_Q1'     :summary.loc['Q1','SR'],\n",
    "            'SR_Q5'     :summary.loc['Q5','SR'],\n",
    "            'SR_LS'     :summary.loc['LS','SR'],\n",
    "            'Mean_Q1'   :summary.loc['Q1','mean'],\n",
    "            'Mean_Q5'   :summary.loc['Q5','mean'],\n",
    "            'Mean_LS'   :summary.loc['LS','mean'],\n",
    "        })\n",
    "        hyper_comb += 1\n",
    "        \n",
    "# Save results\n",
    "val_results = pd.DataFrame(val_results)\n",
    "val_results.to_csv(r'results/{}_val.csv'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc63a11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal l_rate: 0.001\n",
      "Optimal l1_pen: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>hyper_comb</th>\n",
       "      <th>SR_Q1</th>\n",
       "      <th>SR_Q5</th>\n",
       "      <th>SR_LS</th>\n",
       "      <th>Mean_Q1</th>\n",
       "      <th>Mean_Q5</th>\n",
       "      <th>Mean_LS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_rate</th>\n",
       "      <th>l1_pen</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00001</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.079273</td>\n",
       "      <td>0.418706</td>\n",
       "      <td>0.681920</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.007648</td>\n",
       "      <td>0.005902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005</th>\n",
       "      <th>0.00001</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.048775</td>\n",
       "      <td>0.420903</td>\n",
       "      <td>0.616302</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.006075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <th>0.00001</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.031606</td>\n",
       "      <td>0.440019</td>\n",
       "      <td>0.603054</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.007318</td>\n",
       "      <td>0.006562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.043046</td>\n",
       "      <td>0.538062</td>\n",
       "      <td>0.529550</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.007983</td>\n",
       "      <td>0.006942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.032779</td>\n",
       "      <td>0.607010</td>\n",
       "      <td>0.491336</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>0.007395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076926</td>\n",
       "      <td>0.612532</td>\n",
       "      <td>0.454016</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.008230</td>\n",
       "      <td>0.006375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.123511</td>\n",
       "      <td>0.595502</td>\n",
       "      <td>0.286055</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.007445</td>\n",
       "      <td>0.004463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.172966</td>\n",
       "      <td>0.519300</td>\n",
       "      <td>0.198348</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>0.006964</td>\n",
       "      <td>0.002845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00100</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.304939</td>\n",
       "      <td>0.351587</td>\n",
       "      <td>0.164863</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>0.001428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.294437</td>\n",
       "      <td>0.393108</td>\n",
       "      <td>0.006829</td>\n",
       "      <td>0.006182</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005</th>\n",
       "      <th>0.00100</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.372313</td>\n",
       "      <td>0.361182</td>\n",
       "      <td>-0.151376</td>\n",
       "      <td>0.007093</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>-0.001049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <th>0.00100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.414495</td>\n",
       "      <td>0.267217</td>\n",
       "      <td>-0.477385</td>\n",
       "      <td>0.007703</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>-0.003316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Unnamed: 0  hyper_comb     SR_Q1     SR_Q5     SR_LS  \\\n",
       "l_rate l1_pen                                                          \n",
       "0.001  0.00001          11          11  0.079273  0.418706  0.681920   \n",
       "0.005  0.00001           7           7  0.048775  0.420903  0.616302   \n",
       "0.010  0.00001           3           3  0.031606  0.440019  0.603054   \n",
       "0.001  0.00005          10          10  0.043046  0.538062  0.529550   \n",
       "0.005  0.00005           6           6  0.032779  0.607010  0.491336   \n",
       "0.010  0.00005           2           2  0.076926  0.612532  0.454016   \n",
       "0.001  0.00010           9           9  0.123511  0.595502  0.286055   \n",
       "0.005  0.00010           5           5  0.172966  0.519300  0.198348   \n",
       "0.001  0.00100           8           8  0.304939  0.351587  0.164863   \n",
       "0.010  0.00010           1           1  0.294437  0.393108  0.006829   \n",
       "0.005  0.00100           4           4  0.372313  0.361182 -0.151376   \n",
       "0.010  0.00100           0           0  0.414495  0.267217 -0.477385   \n",
       "\n",
       "                 Mean_Q1   Mean_Q5   Mean_LS  \n",
       "l_rate l1_pen                                 \n",
       "0.001  0.00001  0.001747  0.007648  0.005902  \n",
       "0.005  0.00001  0.001112  0.007188  0.006075  \n",
       "0.010  0.00001  0.000756  0.007318  0.006562  \n",
       "0.001  0.00005  0.001042  0.007983  0.006942  \n",
       "0.005  0.00005  0.000808  0.008203  0.007395  \n",
       "0.010  0.00005  0.001854  0.008230  0.006375  \n",
       "0.001  0.00010  0.002981  0.007445  0.004463  \n",
       "0.005  0.00010  0.004120  0.006964  0.002845  \n",
       "0.001  0.00100  0.005268  0.006696  0.001428  \n",
       "0.010  0.00010  0.006182  0.006268  0.000086  \n",
       "0.005  0.00100  0.007093  0.006044 -0.001049  \n",
       "0.010  0.00100  0.007703  0.004387 -0.003316  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select best hyperparemeters (max. SR_LS)\n",
    "val_results = val = pd.read_csv(r'results/{}_val.csv'.format(model_name))\n",
    "val_results = val_results.set_index(['l_rate', 'l1_pen']).sort_values(['SR_LS'], ascending=False)\n",
    "l_rate_opt, l1_pen_opt = tuple([x for x in val_results.iloc[0].name[0:]])\n",
    "print('Optimal l_rate:', l_rate_opt)\n",
    "print('Optimal l1_pen:', l1_pen_opt)\n",
    "val_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5465cf33",
   "metadata": {},
   "source": [
    "## Out-of-Sample: Get Predictions of model with best hyperparameter combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2229e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of model_ix's with best hyperparameter combinations and make ensemble predictions\n",
    "list_model_ix = table[(table['l_rate'] == l_rate_opt) & (table['l1_pen'] == l1_pen_opt)]\n",
    "list_model_ix = list(list_model_ix['model_ix'])\n",
    "\n",
    "# Get list of column names\n",
    "list_col_names = []\n",
    "for ele in list_model_ix:\n",
    "    list_col_names.append('%s_%d'%(model_name, ele))\n",
    "    \n",
    "# Select relevant returns and average predictions\n",
    "test_ret = test[list_col_names].copy()\n",
    "test_ret['y_pred'] = test_ret.mean(axis=1)\n",
    "\n",
    "# Save predictions\n",
    "test_ret = test_ret.reset_index()\n",
    "test_ret = test_ret[['YM', 'permno', 'y_pred']]\n",
    "test_ret.to_csv(r'results/{}_predictions.csv'.format(model_name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
