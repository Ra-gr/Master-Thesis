{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b282f318",
   "metadata": {},
   "source": [
    "# Neural Network with 3 hidden layers\n",
    "\n",
    "### Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f50478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_4772\\1491999960.py:22: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the Random Seed\n",
    "seed_value= 2022\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "import numpy  as np\n",
    "import pandas  as pd\n",
    "import datetime\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.formula.api as smf\n",
    "import tensorflow as tf\n",
    "from keras.models     import Sequential, load_model\n",
    "from keras.layers     import Activation, Dense, LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks  import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l1\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269d0920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seeds(seed_value=2022):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)\n",
    "reset_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed785df8",
   "metadata": {},
   "source": [
    "### Load Dataset - only traditional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d86ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>reprisk_id</th>\n",
       "      <th>prc</th>\n",
       "      <th>vol</th>\n",
       "      <th>mve_m</th>\n",
       "      <th>absacc</th>\n",
       "      <th>acc</th>\n",
       "      <th>aeavol</th>\n",
       "      <th>age</th>\n",
       "      <th>agr</th>\n",
       "      <th>...</th>\n",
       "      <th>sic2_73</th>\n",
       "      <th>sic2_75</th>\n",
       "      <th>sic2_78</th>\n",
       "      <th>sic2_79</th>\n",
       "      <th>sic2_80</th>\n",
       "      <th>sic2_81</th>\n",
       "      <th>sic2_82</th>\n",
       "      <th>sic2_83</th>\n",
       "      <th>sic2_87</th>\n",
       "      <th>sic2_99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>YM</th>\n",
       "      <th>permno</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2007</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2007-01</th>\n",
       "      <th>10025</th>\n",
       "      <td>11903</td>\n",
       "      <td>37172</td>\n",
       "      <td>45.320000</td>\n",
       "      <td>8086.0</td>\n",
       "      <td>3.700557e+05</td>\n",
       "      <td>0.698728</td>\n",
       "      <td>-0.745547</td>\n",
       "      <td>-0.646819</td>\n",
       "      <td>0.457506</td>\n",
       "      <td>-0.979644</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10026</th>\n",
       "      <td>12825</td>\n",
       "      <td>12684</td>\n",
       "      <td>39.689999</td>\n",
       "      <td>7613.0</td>\n",
       "      <td>7.653725e+05</td>\n",
       "      <td>0.577608</td>\n",
       "      <td>-0.635623</td>\n",
       "      <td>-0.393384</td>\n",
       "      <td>0.457506</td>\n",
       "      <td>0.118575</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10042</th>\n",
       "      <td>12139</td>\n",
       "      <td>4832</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>26008.0</td>\n",
       "      <td>3.598898e+04</td>\n",
       "      <td>0.990840</td>\n",
       "      <td>-0.989822</td>\n",
       "      <td>-0.894148</td>\n",
       "      <td>0.457506</td>\n",
       "      <td>-0.989822</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10078</th>\n",
       "      <td>12136</td>\n",
       "      <td>1719</td>\n",
       "      <td>6.130000</td>\n",
       "      <td>11333293.0</td>\n",
       "      <td>2.390900e+07</td>\n",
       "      <td>0.654962</td>\n",
       "      <td>-0.711959</td>\n",
       "      <td>-0.128753</td>\n",
       "      <td>0.905344</td>\n",
       "      <td>-0.147074</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10104</th>\n",
       "      <td>12142</td>\n",
       "      <td>4413</td>\n",
       "      <td>16.430000</td>\n",
       "      <td>7234361.0</td>\n",
       "      <td>8.892640e+07</td>\n",
       "      <td>-0.014758</td>\n",
       "      <td>-0.107379</td>\n",
       "      <td>0.780153</td>\n",
       "      <td>0.905344</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021-12</th>\n",
       "      <th>93304</th>\n",
       "      <td>184167</td>\n",
       "      <td>91339</td>\n",
       "      <td>36.750000</td>\n",
       "      <td>183303.0</td>\n",
       "      <td>1.695898e+06</td>\n",
       "      <td>-0.855522</td>\n",
       "      <td>0.706269</td>\n",
       "      <td>-0.871045</td>\n",
       "      <td>-0.500896</td>\n",
       "      <td>0.613134</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93373</th>\n",
       "      <td>184323</td>\n",
       "      <td>74074</td>\n",
       "      <td>3.020000</td>\n",
       "      <td>528712.0</td>\n",
       "      <td>2.065325e+05</td>\n",
       "      <td>-0.213134</td>\n",
       "      <td>0.143881</td>\n",
       "      <td>0.663284</td>\n",
       "      <td>-0.500896</td>\n",
       "      <td>-0.875821</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93374</th>\n",
       "      <td>184899</td>\n",
       "      <td>64442</td>\n",
       "      <td>74.510002</td>\n",
       "      <td>159495.0</td>\n",
       "      <td>8.587073e+06</td>\n",
       "      <td>-0.514030</td>\n",
       "      <td>0.423284</td>\n",
       "      <td>-0.223881</td>\n",
       "      <td>-0.500896</td>\n",
       "      <td>0.328955</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93423</th>\n",
       "      <td>10567</td>\n",
       "      <td>22547</td>\n",
       "      <td>39.490002</td>\n",
       "      <td>254917.0</td>\n",
       "      <td>3.661156e+06</td>\n",
       "      <td>0.242985</td>\n",
       "      <td>-0.303881</td>\n",
       "      <td>0.560597</td>\n",
       "      <td>0.143881</td>\n",
       "      <td>-0.584478</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93436</th>\n",
       "      <td>184996</td>\n",
       "      <td>24952</td>\n",
       "      <td>936.719971</td>\n",
       "      <td>6361641.0</td>\n",
       "      <td>1.092218e+09</td>\n",
       "      <td>0.584478</td>\n",
       "      <td>-0.620299</td>\n",
       "      <td>-0.362388</td>\n",
       "      <td>-0.500896</td>\n",
       "      <td>0.856716</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338288 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      gvkey  reprisk_id         prc         vol         mve_m  \\\n",
       "year YM      permno                                                             \n",
       "2007 2007-01 10025    11903       37172   45.320000      8086.0  3.700557e+05   \n",
       "             10026    12825       12684   39.689999      7613.0  7.653725e+05   \n",
       "             10042    12139        4832    0.720000     26008.0  3.598898e+04   \n",
       "             10078    12136        1719    6.130000  11333293.0  2.390900e+07   \n",
       "             10104    12142        4413   16.430000   7234361.0  8.892640e+07   \n",
       "...                     ...         ...         ...         ...           ...   \n",
       "2021 2021-12 93304   184167       91339   36.750000    183303.0  1.695898e+06   \n",
       "             93373   184323       74074    3.020000    528712.0  2.065325e+05   \n",
       "             93374   184899       64442   74.510002    159495.0  8.587073e+06   \n",
       "             93423    10567       22547   39.490002    254917.0  3.661156e+06   \n",
       "             93436   184996       24952  936.719971   6361641.0  1.092218e+09   \n",
       "\n",
       "                       absacc       acc    aeavol       age       agr  ...  \\\n",
       "year YM      permno                                                    ...   \n",
       "2007 2007-01 10025   0.698728 -0.745547 -0.646819  0.457506 -0.979644  ...   \n",
       "             10026   0.577608 -0.635623 -0.393384  0.457506  0.118575  ...   \n",
       "             10042   0.990840 -0.989822 -0.894148  0.457506 -0.989822  ...   \n",
       "             10078   0.654962 -0.711959 -0.128753  0.905344 -0.147074  ...   \n",
       "             10104  -0.014758 -0.107379  0.780153  0.905344  0.770992  ...   \n",
       "...                       ...       ...       ...       ...       ...  ...   \n",
       "2021 2021-12 93304  -0.855522  0.706269 -0.871045 -0.500896  0.613134  ...   \n",
       "             93373  -0.213134  0.143881  0.663284 -0.500896 -0.875821  ...   \n",
       "             93374  -0.514030  0.423284 -0.223881 -0.500896  0.328955  ...   \n",
       "             93423   0.242985 -0.303881  0.560597  0.143881 -0.584478  ...   \n",
       "             93436   0.584478 -0.620299 -0.362388 -0.500896  0.856716  ...   \n",
       "\n",
       "                     sic2_73  sic2_75  sic2_78  sic2_79  sic2_80  sic2_81  \\\n",
       "year YM      permno                                                         \n",
       "2007 2007-01 10025         0        0        0        0        0        0   \n",
       "             10026         0        0        0        0        0        0   \n",
       "             10042         0        0        0        0        0        0   \n",
       "             10078         0        0        0        0        0        0   \n",
       "             10104         1        0        0        0        0        0   \n",
       "...                      ...      ...      ...      ...      ...      ...   \n",
       "2021 2021-12 93304         0        0        0        0        0        0   \n",
       "             93373         0        0        0        0        0        0   \n",
       "             93374         0        0        0        0        0        0   \n",
       "             93423         0        0        0        1        0        0   \n",
       "             93436         0        0        0        0        0        0   \n",
       "\n",
       "                     sic2_82  sic2_83  sic2_87  sic2_99  \n",
       "year YM      permno                                      \n",
       "2007 2007-01 10025         0        0        0        0  \n",
       "             10026         0        0        0        0  \n",
       "             10042         0        0        0        0  \n",
       "             10078         0        0        0        0  \n",
       "             10104         0        0        0        0  \n",
       "...                      ...      ...      ...      ...  \n",
       "2021 2021-12 93304         0        0        0        0  \n",
       "             93373         0        0        0        0  \n",
       "             93374         0        0        0        0  \n",
       "             93423         0        0        0        0  \n",
       "             93436         0        0        0        0  \n",
       "\n",
       "[338288 rows x 188 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load monthly firm characteristics raw data\n",
    "df = pd.read_parquet('C:/Users/rafae/Documents/HSG/Master Thesis/Data/Final/data07_model_input.parquet')\n",
    "df = df.sort_values(by=['YM', 'permno'])\n",
    "df = df.set_index(['year', 'YM', 'permno'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10fdc476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((338288, 162), (338288, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only relevant columns for X and Y (exclude industry & reprisk rating dummy for now)\n",
    "info_vars = ['YM', 'year', 'permno', 'gvkey', 'reprisk_id', 'prc', 'vol', 'mve_m']\n",
    "X_vars = ['absacc', 'acc', 'aeavol', 'age', 'agr', 'baspread', 'beta', 'betasq', 'bm', 'bm_ia', 'cash', 'cashdebt',\n",
    "          'cashpr', 'cfp', 'cfp_ia', 'chatoia', 'chcsho', 'chempia', 'chinv', 'chmom', 'chpmia', 'chtx', 'cinvest',\n",
    "          'convind', 'currat', 'depr', 'divi', 'divo', 'dolvol', 'dy', 'ear', 'egr', 'ep', 'gma', 'grcapx', 'grltnoa',\n",
    "          'herf', 'hire', 'idiovol', 'ill', 'indmom', 'invest', 'lev', 'lgr', 'maxret', 'mom12m', 'mom1m', 'mom36m',\n",
    "          'mom6m', 'ms', 'mve', 'mve_ia', 'nincr', 'operprof', 'orgcap', 'pchcapx_ia', 'pchcurrat', 'pchdepr',\n",
    "          'pchgm_pchsale', 'pchquick', 'pchsale_pchinvt', 'pchsale_pchrect', 'pchsale_pchxsga', 'pchsaleinv', 'pctacc',\n",
    "          'pricedelay', 'ps', 'quick', 'rd', 'rd_mve', 'rd_sale', 'realestate', 'retvol', 'roaq', 'roavol', 'roeq',\n",
    "          'roic', 'rsup', 'salecash', 'saleinv', 'salerec', 'secured', 'securedind', 'sgr', 'sin', 'sp', 'std_dolvol',\n",
    "          'std_turn', 'stdacc', 'stdcf', 'tang', 'tb', 'turn', 'zerotrade']\n",
    "sic2_vars = [col for col in df if col.startswith('sic2')]\n",
    "reprisk_vars = ['country_sector_average', 'country_sector_average_01', 'current_rri', 'current_rri_01',\n",
    "                'peak_rri', 'peak_rri_01', 'trend_rri', 'trend_rri_01']\n",
    "reprisk_rating_vars = [col for col in df if col.startswith('reprisk_rating')]\n",
    "Y_vars = ['ret', 'ret_wins', 'ret_ex']\n",
    "\n",
    "# X\n",
    "X = df[X_vars + sic2_vars]\n",
    "\n",
    "# Y\n",
    "Y = df[['ret_ex']]\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9340331b",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization: 4-Fold CV (12y/4 = 3y) and 3y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bdbdbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training (12y - 80%) and Test set (3y - 20%)\n",
    "X_trai = X.loc['2007':'2018']\n",
    "Y_trai = Y.loc['2007':'2018']\n",
    "\n",
    "X_test = X.loc['2019':'2021']\n",
    "Y_test = Y.loc['2019':'2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51422f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2007', '2008', '2009'] ['2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018']\n",
      "['2010', '2011', '2012'] ['2007', '2008', '2009', '2013', '2014', '2015', '2016', '2017', '2018']\n",
      "['2013', '2014', '2015'] ['2007', '2008', '2009', '2010', '2011', '2012', '2016', '2017', '2018']\n",
      "['2016', '2017', '2018'] ['2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015']\n"
     ]
    }
   ],
   "source": [
    "# 4-Fold cross validation (9y training and 3y validation)\n",
    "K_FOLDs = 4\n",
    "YEARS = list(X_trai.index.unique(level='year').astype('str')) \n",
    "TOT = len(YEARS)\n",
    "TRA = int(TOT* (K_FOLDs-1) / K_FOLDs)\n",
    "OFF = TOT - TRA\n",
    "\n",
    "for FOLD in range(K_FOLDs):\n",
    "    VALI = YEARS[(FOLD*OFF):((FOLD+1)*OFF)]\n",
    "    TRAI = [x for x in YEARS if x not in VALI]\n",
    "    print(VALI, TRAI)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "277e86f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'NN3_trad'\n",
    "\n",
    "def create_NN3(l_rate=0.01, l1_pen=0.0001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32,\n",
    "                    activation='relu',\n",
    "                    input_dim=X_trai.shape[1],\n",
    "                    kernel_regularizer=l1(l1_pen)))\n",
    "    model.add(Dense(16,\n",
    "                    activation='relu',\n",
    "                    kernel_regularizer=l1(l1_pen)))\n",
    "    model.add(Dense(8,\n",
    "                    activation='relu',\n",
    "                    kernel_regularizer=l1(l1_pen)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=l_rate))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91c78e0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• 0 : Epoch 12: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 1 : Epoch 12: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 2 : Epoch 12: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 11: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 3 : Epoch 15: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 4 : Epoch 12: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 5 : Epoch 12: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 11: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 6 : Epoch 13: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 7 : Epoch 10: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 8 : Epoch 12: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 9 : Epoch 8: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 10 : Epoch 12: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 5s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 11 : Epoch 21: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 5s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 12 : Epoch 11: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 14: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 11: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 13 : Epoch 10: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 16: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 16: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 14 : Epoch 9: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 11: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 15 : Epoch 20: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 17: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 16 : Epoch 10: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 11: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 17 : Epoch 17: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 11: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 16: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 18 : Epoch 10: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 19 : Epoch 19: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 16: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 20 : Epoch 36: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 24: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 26: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 21 : Epoch 34: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 33: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 30: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 32: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 22 : Epoch 38: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 32: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 38: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 27: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 23 : Epoch 30: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 26: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 27: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 24 : Epoch 19: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 24: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 24: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 29: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 25 : Epoch 42: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 41: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 42: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 39: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 26 : Epoch 26: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 26: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 25: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 29: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 27 : Epoch 29: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 26: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 27: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 31: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 28 : Epoch 23: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 31: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 28: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 29 : Epoch 22: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 28: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 26: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 28: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 30 : Epoch 11: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 11: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 31 : Epoch 13: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 32 : Epoch 12: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 33 : Epoch 13: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 11: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 34 : Epoch 8: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 35 : Epoch 14: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 14: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 36 : Epoch 20: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 37 : Epoch 13: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 16: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 38 : Epoch 12: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 11: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 39 : Epoch 13: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 11: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 9: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 8: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 40 : Epoch 13: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 11: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 41 : Epoch 15: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 20: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 42 : Epoch 15: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 14: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 14: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 43 : Epoch 15: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 44 : Epoch 11: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 45 : Epoch 20: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 46 : Epoch 16: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 47 : Epoch 17: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 48 : Epoch 14: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 14: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 49 : Epoch 13: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 11: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 11: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 11: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 50 : Epoch 36: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 27: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 29: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 30: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 51 : Epoch 44: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 34: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 41: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 41: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 52 : Epoch 38: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 37: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 36: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 36: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 53 : Epoch 30: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 35: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 32: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 33: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 54 : Epoch 32: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 24: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 25: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 29: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 55 : Epoch 55: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 49: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 55: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 50: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 56 : Epoch 34: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 29: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 32: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 29: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 57 : Epoch 36: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 36: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 34: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 40: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 58 : Epoch 32: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 31: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 31: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 28: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 59 : Epoch 32: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 30: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 28: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 28: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 60 : Epoch 11: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 10: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 14: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 61 : Epoch 13: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 17: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 62 : Epoch 27: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 14: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 63 : Epoch 13: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 17: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 64 : Epoch 15: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 65 : Epoch 25: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 28: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 26: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 28: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 66 : Epoch 16: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 14: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 16: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 67 : Epoch 21: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 68 : Epoch 14: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 12: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 14: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 69 : Epoch 18: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 70 : Epoch 20: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 71 : Epoch 23: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 32: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 24: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 72 : Epoch 27: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 29: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 73 : Epoch 18: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 17: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 74 : Epoch 26: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 24: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 75 : Epoch 46: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 37: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 39: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 36: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 76 : Epoch 20: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 77 : Epoch 25: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 32: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 27: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 25: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 78 : Epoch 26: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 79 : Epoch 19: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 17: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 16: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 80 : Epoch 36: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 30: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 53: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 41: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 81 : Epoch 44: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 44: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 71: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 66: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 82 : Epoch 47: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 44: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 64: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 59: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 83 : Epoch 42: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 46: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 55: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 52: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 84 : Epoch 32: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 45: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 54: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 46: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 85 : Epoch 78: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 70: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 74: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 75: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 86 : Epoch 41: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 37: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 53: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 55: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 87 : Epoch 50: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 62: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 59: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 61: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 88 : Epoch 48: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 54: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 56: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 48: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 89 : Epoch 45: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 48: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 57: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 48: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 90 : Epoch 11: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 17: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 91 : Epoch 19: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 24: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 92 : Epoch 27: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 93 : Epoch 13: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 13: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 94 : Epoch 15: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 95 : Epoch 28: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 28: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 34: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 36: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 96 : Epoch 16: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 14: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 97 : Epoch 19: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 26: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 26: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 25: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 98 : Epoch 14: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "1929/1929 [==============================] - 4s 2ms/step\n",
      "Epoch 14: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 99 : Epoch 18: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 16: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 100 : Epoch 33: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 30s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 101 : Epoch 23: early stopping\n",
      "2230/2230 [==============================] - 4s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 39: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 25: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 102 : Epoch 27: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: early stopping\n",
      "2193/2193 [==============================] - 4s 2ms/step\n",
      "Epoch 42: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 35: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 103 : Epoch 18: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 30s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 30: early stopping\n",
      "2156/2156 [==============================] - 4s 2ms/step\n",
      "Epoch 31: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 104 : Epoch 26: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 24: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 105 : Epoch 46: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 32s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 50: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 45: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 106 : Epoch 20: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 25: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 107 : Epoch 31: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 30s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 37: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 25: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 108 : Epoch 23: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 27: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 25: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 109 : Epoch 19: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 27: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 22: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 110 : Epoch 40: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 53: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 41: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 111 : Epoch 64: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 30s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 80: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 53: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 112 : Epoch 47: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 71: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 59: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 113 : Epoch 42: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 30s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 53: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 41: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 114 : Epoch 38: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 59: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 46: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 115 : Epoch 82: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 86: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 88: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 116 : Epoch 53: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 53: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 55: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 117 : Epoch 50: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 75: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 83: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 118 : Epoch 48: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 63: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 48: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 119 : Epoch 47: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 60: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 60: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 120 : Epoch 20: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 121 : Epoch 22: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 30s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 27: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 25: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 122 : Epoch 27: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 30s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 32: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 28: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 123 : Epoch 21: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 30s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 29: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 124 : Epoch 17: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 15: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 125 : Epoch 38: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 38: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 43: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 126 : Epoch 16: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 34: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 127 : Epoch 29: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 37: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 24: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 128 : Epoch 21: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 33: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 129 : Epoch 18: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 25: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 24: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 130 : Epoch 20: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 20: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 23: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 131 : Epoch 23: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 30: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 18: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 132 : Epoch 27: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 30s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 31: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 33: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 133 : Epoch 26: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 24: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 134 : Epoch 26: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 30s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 37: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 19: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 135 : Epoch 45: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 43: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 43: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 136 : Epoch 30: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 35: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 26: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 137 : Epoch 31: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:30"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 39: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 25: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 138 : Epoch 26: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 26: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 21: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 139 : Epoch 19: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 30s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 27: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 28: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 140 : Epoch 46: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 29: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 30: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 141 : Epoch 59: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 41: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 32: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 142 : Epoch 67: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 45: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 48: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 143 : Epoch 60: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 5s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 38: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 34: early stopping\n",
      "2066/2066 [==============================] - 5s 2ms/step\n",
      "• 144 : Epoch 57: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 41: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 38: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 145 : Epoch 92: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 30s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 65: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 54: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 146 : Epoch 41: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 38: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 38: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 147 : Epoch 66: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 42: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 45: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 148 : Epoch 53: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "   1/1929 [..............................] - ETA: 1:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 40: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 46: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n",
      "• 149 : Epoch 50: early stopping\n",
      "2230/2230 [==============================] - 5s 2ms/step\n",
      "  16/1929 [..............................] - ETA: 6s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929/1929 [==============================] - 4s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_1696\\2818418857.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: early stopping\n",
      "2193/2193 [==============================] - 5s 2ms/step\n",
      "Epoch 38: early stopping\n",
      "2156/2156 [==============================] - 5s 2ms/step\n",
      "Epoch 35: early stopping\n",
      "2066/2066 [==============================] - 4s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter optimization\n",
    "Y_val_preds = Y_trai.copy()\n",
    "Y_test_preds = Y_test.copy()\n",
    "results = []\n",
    "\n",
    "earlyStopping  = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
    "\n",
    "model_ix = 0\n",
    "for l1_pen in [0.001, 0.0005, 0.0001, 0.00005, 0.00001]:\n",
    "        for l_rate in [0.01, 0.005, 0.001]:\n",
    "            for ensemble in list(range(0,10)):\n",
    "                print(\"•\", model_ix, ':',  end=' ')\n",
    "                    \n",
    "                for FOLD in range(K_FOLDs):\n",
    "                    VALI = YEARS[(FOLD*OFF):((FOLD+1)*OFF)]\n",
    "                    TRAI = [x for x in YEARS if x not in VALI]\n",
    "                        \n",
    "                    mcp_save = ModelCheckpoint(\n",
    "                        '%s/%s_%d_%d.h5'%(model_name, model_name, model_ix, FOLD),\n",
    "                        save_best_only=True, monitor='val_loss', mode='min', save_weights_only=True\n",
    "                    )\n",
    "\n",
    "                    reset_seeds(ensemble*10000)\n",
    "                        \n",
    "                    NN_model = create_NN3(l_rate, l1_pen)\n",
    "                        \n",
    "                    history = NN_model.fit(\n",
    "                        X_trai.loc[TRAI], Y_trai.loc[TRAI],\n",
    "                        validation_data=(X_trai.loc[VALI], Y_trai.loc[VALI]),\n",
    "                        epochs=200, verbose=0, shuffle=True, batch_size=2000,\n",
    "                        callbacks=[earlyStopping, mcp_save]\n",
    "                    )\n",
    "                    tra_loss = np.min(history.history['loss'])\n",
    "                    val_loss = np.min(history.history['val_loss'])\n",
    "\n",
    "                    results.append({\n",
    "                        'model_ix' :model_ix,\n",
    "                        'l_rate'   :l_rate,\n",
    "                        'l1_pen'   :l1_pen,\n",
    "                        'fold'     :FOLD,\n",
    "                        'tra_loss' :tra_loss,\n",
    "                        'val_loss' :val_loss\n",
    "                    })\n",
    "                    \n",
    "                    # Calculate validation predictions\n",
    "                    best_model = create_NN3(l_rate, l1_pen)\n",
    "                    best_model.load_weights(r'%s/%s_%d_%d.h5'%(model_name, model_name, model_ix, FOLD));\n",
    "                    Y_val_preds.loc[VALI, '%s_%d'%(model_name, model_ix)] = best_model.predict(X_trai.loc[VALI])\n",
    "                    \n",
    "                    # Calculate predictions for test data, if FOLD = 0\n",
    "                    if FOLD==0:\n",
    "                        Y_test_preds.loc[['2019','2020', '2021'], '%s_%d'%(model_name, model_ix)] = best_model.predict(X_test)\n",
    "\n",
    "                model_ix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "135e970f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ret_ex</th>\n",
       "      <th>NN3_trad_0</th>\n",
       "      <th>NN3_trad_1</th>\n",
       "      <th>NN3_trad_2</th>\n",
       "      <th>NN3_trad_3</th>\n",
       "      <th>NN3_trad_4</th>\n",
       "      <th>NN3_trad_5</th>\n",
       "      <th>NN3_trad_6</th>\n",
       "      <th>NN3_trad_7</th>\n",
       "      <th>NN3_trad_8</th>\n",
       "      <th>...</th>\n",
       "      <th>NN3_trad_140</th>\n",
       "      <th>NN3_trad_141</th>\n",
       "      <th>NN3_trad_142</th>\n",
       "      <th>NN3_trad_143</th>\n",
       "      <th>NN3_trad_144</th>\n",
       "      <th>NN3_trad_145</th>\n",
       "      <th>NN3_trad_146</th>\n",
       "      <th>NN3_trad_147</th>\n",
       "      <th>NN3_trad_148</th>\n",
       "      <th>NN3_trad_149</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>YM</th>\n",
       "      <th>permno</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2007</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2007-01</th>\n",
       "      <th>10025</th>\n",
       "      <td>-0.031894</td>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013851</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.016665</td>\n",
       "      <td>0.010455</td>\n",
       "      <td>0.013330</td>\n",
       "      <td>0.009923</td>\n",
       "      <td>0.011892</td>\n",
       "      <td>0.014946</td>\n",
       "      <td>0.013262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10026</th>\n",
       "      <td>-0.042317</td>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010050</td>\n",
       "      <td>0.010498</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.010487</td>\n",
       "      <td>0.014244</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.012013</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>0.013422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10042</th>\n",
       "      <td>-0.125751</td>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027764</td>\n",
       "      <td>-0.050386</td>\n",
       "      <td>-0.019268</td>\n",
       "      <td>-0.026286</td>\n",
       "      <td>-0.029779</td>\n",
       "      <td>-0.031946</td>\n",
       "      <td>-0.011458</td>\n",
       "      <td>-0.036203</td>\n",
       "      <td>-0.035053</td>\n",
       "      <td>-0.046421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10078</th>\n",
       "      <td>-0.080607</td>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012945</td>\n",
       "      <td>0.010407</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.011381</td>\n",
       "      <td>0.016308</td>\n",
       "      <td>0.012114</td>\n",
       "      <td>0.011124</td>\n",
       "      <td>0.011059</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>0.014028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10104</th>\n",
       "      <td>-0.046341</td>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011418</td>\n",
       "      <td>0.010533</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.013091</td>\n",
       "      <td>0.015675</td>\n",
       "      <td>0.013872</td>\n",
       "      <td>0.010874</td>\n",
       "      <td>0.016558</td>\n",
       "      <td>0.014054</td>\n",
       "      <td>0.016082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2018</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2018-12</th>\n",
       "      <th>93420</th>\n",
       "      <td>0.086508</td>\n",
       "      <td>0.010904</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.008059</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>0.006232</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.00718</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029808</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>-0.028944</td>\n",
       "      <td>-0.001328</td>\n",
       "      <td>0.019583</td>\n",
       "      <td>-0.023166</td>\n",
       "      <td>-0.009056</td>\n",
       "      <td>-0.014344</td>\n",
       "      <td>-0.036547</td>\n",
       "      <td>0.006188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93422</th>\n",
       "      <td>0.466817</td>\n",
       "      <td>0.010904</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.008059</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>0.006232</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.00718</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006863</td>\n",
       "      <td>-0.033720</td>\n",
       "      <td>-0.046797</td>\n",
       "      <td>-0.039256</td>\n",
       "      <td>-0.023008</td>\n",
       "      <td>-0.044846</td>\n",
       "      <td>-0.037428</td>\n",
       "      <td>-0.015359</td>\n",
       "      <td>-0.039859</td>\n",
       "      <td>-0.022223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93423</th>\n",
       "      <td>0.105036</td>\n",
       "      <td>0.010904</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.008059</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>0.006232</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.00718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009498</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>0.006965</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>0.012891</td>\n",
       "      <td>0.009157</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>0.013519</td>\n",
       "      <td>0.011953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93429</th>\n",
       "      <td>-0.048712</td>\n",
       "      <td>0.010904</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.008059</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>0.006232</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.00718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016446</td>\n",
       "      <td>0.011639</td>\n",
       "      <td>0.015341</td>\n",
       "      <td>0.006965</td>\n",
       "      <td>0.014032</td>\n",
       "      <td>0.013194</td>\n",
       "      <td>0.008959</td>\n",
       "      <td>0.010861</td>\n",
       "      <td>0.017418</td>\n",
       "      <td>0.013101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93436</th>\n",
       "      <td>-0.079564</td>\n",
       "      <td>0.010904</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.008059</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>0.006232</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.00718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.020902</td>\n",
       "      <td>0.007329</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>0.013994</td>\n",
       "      <td>0.009526</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>-0.007312</td>\n",
       "      <td>0.012306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276564 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ret_ex  NN3_trad_0  NN3_trad_1  NN3_trad_2  NN3_trad_3  \\\n",
       "year YM      permno                                                             \n",
       "2007 2007-01 10025  -0.031894    0.008004    0.008919    0.009752    0.008152   \n",
       "             10026  -0.042317    0.008004    0.008919    0.009752    0.008152   \n",
       "             10042  -0.125751    0.008004    0.008919    0.009752    0.008152   \n",
       "             10078  -0.080607    0.008004    0.008919    0.009752    0.008152   \n",
       "             10104  -0.046341    0.008004    0.008919    0.009752    0.008152   \n",
       "...                       ...         ...         ...         ...         ...   \n",
       "2018 2018-12 93420   0.086508    0.010904    0.002437    0.008059    0.004732   \n",
       "             93422   0.466817    0.010904    0.002437    0.008059    0.004732   \n",
       "             93423   0.105036    0.010904    0.002437    0.008059    0.004732   \n",
       "             93429  -0.048712    0.010904    0.002437    0.008059    0.004732   \n",
       "             93436  -0.079564    0.010904    0.002437    0.008059    0.004732   \n",
       "\n",
       "                     NN3_trad_4  NN3_trad_5  NN3_trad_6  NN3_trad_7  \\\n",
       "year YM      permno                                                   \n",
       "2007 2007-01 10025     0.008095    0.007825    0.009095    0.005856   \n",
       "             10026     0.008095    0.007825    0.009095    0.005856   \n",
       "             10042     0.008095    0.007825    0.009095    0.005856   \n",
       "             10078     0.008095    0.007825    0.009095    0.005856   \n",
       "             10104     0.008095    0.007825    0.009095    0.005856   \n",
       "...                         ...         ...         ...         ...   \n",
       "2018 2018-12 93420     0.011261    0.006232    0.008138    0.001793   \n",
       "             93422     0.011261    0.006232    0.008138    0.001793   \n",
       "             93423     0.011261    0.006232    0.008138    0.001793   \n",
       "             93429     0.011261    0.006232    0.008138    0.001793   \n",
       "             93436     0.011261    0.006232    0.008138    0.001793   \n",
       "\n",
       "                     NN3_trad_8  ...  NN3_trad_140  NN3_trad_141  \\\n",
       "year YM      permno              ...                               \n",
       "2007 2007-01 10025      0.00513  ...      0.013851      0.010490   \n",
       "             10026      0.00513  ...      0.010050      0.010498   \n",
       "             10042      0.00513  ...     -0.027764     -0.050386   \n",
       "             10078      0.00513  ...      0.012945      0.010407   \n",
       "             10104      0.00513  ...      0.011418      0.010533   \n",
       "...                         ...  ...           ...           ...   \n",
       "2018 2018-12 93420      0.00718  ...     -0.029808      0.001112   \n",
       "             93422      0.00718  ...     -0.006863     -0.033720   \n",
       "             93423      0.00718  ...      0.009498      0.006160   \n",
       "             93429      0.00718  ...      0.016446      0.011639   \n",
       "             93436      0.00718  ...      0.003162      0.002915   \n",
       "\n",
       "                     NN3_trad_142  NN3_trad_143  NN3_trad_144  NN3_trad_145  \\\n",
       "year YM      permno                                                           \n",
       "2007 2007-01 10025       0.012259      0.016665      0.010455      0.013330   \n",
       "             10026       0.012259      0.010487      0.014244      0.013000   \n",
       "             10042      -0.019268     -0.026286     -0.029779     -0.031946   \n",
       "             10078       0.012259      0.011381      0.016308      0.012114   \n",
       "             10104       0.012259      0.013091      0.015675      0.013872   \n",
       "...                           ...           ...           ...           ...   \n",
       "2018 2018-12 93420      -0.028944     -0.001328      0.019583     -0.023166   \n",
       "             93422      -0.046797     -0.039256     -0.023008     -0.044846   \n",
       "             93423       0.004473      0.006965      0.002910      0.012891   \n",
       "             93429       0.015341      0.006965      0.014032      0.013194   \n",
       "             93436       0.020902      0.007329      0.003668      0.013994   \n",
       "\n",
       "                     NN3_trad_146  NN3_trad_147  NN3_trad_148  NN3_trad_149  \n",
       "year YM      permno                                                          \n",
       "2007 2007-01 10025       0.009923      0.011892      0.014946      0.013262  \n",
       "             10026       0.012013      0.009373      0.010411      0.013422  \n",
       "             10042      -0.011458     -0.036203     -0.035053     -0.046421  \n",
       "             10078       0.011124      0.011059      0.009351      0.014028  \n",
       "             10104       0.010874      0.016558      0.014054      0.016082  \n",
       "...                           ...           ...           ...           ...  \n",
       "2018 2018-12 93420      -0.009056     -0.014344     -0.036547      0.006188  \n",
       "             93422      -0.037428     -0.015359     -0.039859     -0.022223  \n",
       "             93423       0.009157      0.009035      0.013519      0.011953  \n",
       "             93429       0.008959      0.010861      0.017418      0.013101  \n",
       "             93436       0.009526      0.003007     -0.007312      0.012306  \n",
       "\n",
       "[276564 rows x 151 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Y_val_preds\n",
    "Y_val_preds.to_csv(r'%s/%s_val_preds.csv'%(model_name, model_name))\n",
    "Y_val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d373e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ret_ex</th>\n",
       "      <th>NN3_trad_0</th>\n",
       "      <th>NN3_trad_1</th>\n",
       "      <th>NN3_trad_2</th>\n",
       "      <th>NN3_trad_3</th>\n",
       "      <th>NN3_trad_4</th>\n",
       "      <th>NN3_trad_5</th>\n",
       "      <th>NN3_trad_6</th>\n",
       "      <th>NN3_trad_7</th>\n",
       "      <th>NN3_trad_8</th>\n",
       "      <th>...</th>\n",
       "      <th>NN3_trad_140</th>\n",
       "      <th>NN3_trad_141</th>\n",
       "      <th>NN3_trad_142</th>\n",
       "      <th>NN3_trad_143</th>\n",
       "      <th>NN3_trad_144</th>\n",
       "      <th>NN3_trad_145</th>\n",
       "      <th>NN3_trad_146</th>\n",
       "      <th>NN3_trad_147</th>\n",
       "      <th>NN3_trad_148</th>\n",
       "      <th>NN3_trad_149</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>YM</th>\n",
       "      <th>permno</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2019</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2019-01</th>\n",
       "      <th>10026</th>\n",
       "      <td>0.004225</td>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008643</td>\n",
       "      <td>0.010566</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.009159</td>\n",
       "      <td>0.010160</td>\n",
       "      <td>0.012875</td>\n",
       "      <td>0.012014</td>\n",
       "      <td>0.008049</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>0.011770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10104</th>\n",
       "      <td>0.036026</td>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007877</td>\n",
       "      <td>0.010578</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.008483</td>\n",
       "      <td>0.015856</td>\n",
       "      <td>0.013279</td>\n",
       "      <td>0.011068</td>\n",
       "      <td>0.013024</td>\n",
       "      <td>0.010416</td>\n",
       "      <td>0.015402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10107</th>\n",
       "      <td>0.075381</td>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>0.010510</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.010773</td>\n",
       "      <td>0.014458</td>\n",
       "      <td>0.012880</td>\n",
       "      <td>0.011959</td>\n",
       "      <td>0.009425</td>\n",
       "      <td>0.010368</td>\n",
       "      <td>0.011568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10138</th>\n",
       "      <td>0.072777</td>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.010468</td>\n",
       "      <td>0.011627</td>\n",
       "      <td>0.006776</td>\n",
       "      <td>0.009122</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.011959</td>\n",
       "      <td>0.009056</td>\n",
       "      <td>0.008180</td>\n",
       "      <td>0.014615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10145</th>\n",
       "      <td>0.076596</td>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006492</td>\n",
       "      <td>0.010408</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.006845</td>\n",
       "      <td>0.009955</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.012116</td>\n",
       "      <td>0.013925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021-12</th>\n",
       "      <th>93304</th>\n",
       "      <td>-0.096386</td>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012077</td>\n",
       "      <td>0.010661</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.012530</td>\n",
       "      <td>0.010848</td>\n",
       "      <td>0.010504</td>\n",
       "      <td>0.010649</td>\n",
       "      <td>0.008006</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>0.013521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93373</th>\n",
       "      <td>-0.019481</td>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005942</td>\n",
       "      <td>-0.019556</td>\n",
       "      <td>-0.016302</td>\n",
       "      <td>-0.013161</td>\n",
       "      <td>-0.019003</td>\n",
       "      <td>-0.010910</td>\n",
       "      <td>-0.008803</td>\n",
       "      <td>-0.008924</td>\n",
       "      <td>-0.030353</td>\n",
       "      <td>-0.030865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93374</th>\n",
       "      <td>-0.047552</td>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.010444</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.009994</td>\n",
       "      <td>0.016466</td>\n",
       "      <td>0.013127</td>\n",
       "      <td>0.011274</td>\n",
       "      <td>0.012942</td>\n",
       "      <td>0.008641</td>\n",
       "      <td>0.015326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93423</th>\n",
       "      <td>-0.072569</td>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013160</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.012746</td>\n",
       "      <td>0.016168</td>\n",
       "      <td>0.007342</td>\n",
       "      <td>0.010649</td>\n",
       "      <td>0.013714</td>\n",
       "      <td>0.013107</td>\n",
       "      <td>0.015131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93436</th>\n",
       "      <td>-0.113609</td>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001168</td>\n",
       "      <td>0.004194</td>\n",
       "      <td>-0.013975</td>\n",
       "      <td>0.004441</td>\n",
       "      <td>0.012383</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.011802</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.007745</td>\n",
       "      <td>0.014447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61724 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ret_ex  NN3_trad_0  NN3_trad_1  NN3_trad_2  NN3_trad_3  \\\n",
       "year YM      permno                                                             \n",
       "2019 2019-01 10026   0.004225    0.008004    0.008919    0.009752    0.008152   \n",
       "             10104   0.036026    0.008004    0.008919    0.009752    0.008152   \n",
       "             10107   0.075381    0.008004    0.008919    0.009752    0.008152   \n",
       "             10138   0.072777    0.008004    0.008919    0.009752    0.008152   \n",
       "             10145   0.076596    0.008004    0.008919    0.009752    0.008152   \n",
       "...                       ...         ...         ...         ...         ...   \n",
       "2021 2021-12 93304  -0.096386    0.008004    0.008919    0.009752    0.008152   \n",
       "             93373  -0.019481    0.008004    0.008919    0.009752    0.008152   \n",
       "             93374  -0.047552    0.008004    0.008919    0.009752    0.008152   \n",
       "             93423  -0.072569    0.008004    0.008919    0.009752    0.008152   \n",
       "             93436  -0.113609    0.008004    0.008919    0.009752    0.008152   \n",
       "\n",
       "                     NN3_trad_4  NN3_trad_5  NN3_trad_6  NN3_trad_7  \\\n",
       "year YM      permno                                                   \n",
       "2019 2019-01 10026     0.008095    0.007825    0.009095    0.005856   \n",
       "             10104     0.008095    0.007825    0.009095    0.005856   \n",
       "             10107     0.008095    0.007825    0.009095    0.005856   \n",
       "             10138     0.008095    0.007825    0.009095    0.005856   \n",
       "             10145     0.008095    0.007825    0.009095    0.005856   \n",
       "...                         ...         ...         ...         ...   \n",
       "2021 2021-12 93304     0.008095    0.007825    0.009095    0.005856   \n",
       "             93373     0.008095    0.007825    0.009095    0.005856   \n",
       "             93374     0.008095    0.007825    0.009095    0.005856   \n",
       "             93423     0.008095    0.007825    0.009095    0.005856   \n",
       "             93436     0.008095    0.007825    0.009095    0.005856   \n",
       "\n",
       "                     NN3_trad_8  ...  NN3_trad_140  NN3_trad_141  \\\n",
       "year YM      permno              ...                               \n",
       "2019 2019-01 10026      0.00513  ...      0.008643      0.010566   \n",
       "             10104      0.00513  ...      0.007877      0.010578   \n",
       "             10107      0.00513  ...      0.003714      0.010510   \n",
       "             10138      0.00513  ...      0.007042      0.010468   \n",
       "             10145      0.00513  ...      0.006492      0.010408   \n",
       "...                         ...  ...           ...           ...   \n",
       "2021 2021-12 93304      0.00513  ...      0.012077      0.010661   \n",
       "             93373      0.00513  ...     -0.005942     -0.019556   \n",
       "             93374      0.00513  ...      0.009092      0.010444   \n",
       "             93423      0.00513  ...      0.013160      0.010636   \n",
       "             93436      0.00513  ...     -0.001168      0.004194   \n",
       "\n",
       "                     NN3_trad_142  NN3_trad_143  NN3_trad_144  NN3_trad_145  \\\n",
       "year YM      permno                                                           \n",
       "2019 2019-01 10026       0.012259      0.009159      0.010160      0.012875   \n",
       "             10104       0.012259      0.008483      0.015856      0.013279   \n",
       "             10107       0.012259      0.010773      0.014458      0.012880   \n",
       "             10138       0.011627      0.006776      0.009122      0.010100   \n",
       "             10145       0.012259      0.006845      0.009955      0.007526   \n",
       "...                           ...           ...           ...           ...   \n",
       "2021 2021-12 93304       0.012259      0.012530      0.010848      0.010504   \n",
       "             93373      -0.016302     -0.013161     -0.019003     -0.010910   \n",
       "             93374       0.012259      0.009994      0.016466      0.013127   \n",
       "             93423       0.012259      0.012746      0.016168      0.007342   \n",
       "             93436      -0.013975      0.004441      0.012383      0.006642   \n",
       "\n",
       "                     NN3_trad_146  NN3_trad_147  NN3_trad_148  NN3_trad_149  \n",
       "year YM      permno                                                          \n",
       "2019 2019-01 10026       0.012014      0.008049      0.010711      0.011770  \n",
       "             10104       0.011068      0.013024      0.010416      0.015402  \n",
       "             10107       0.011959      0.009425      0.010368      0.011568  \n",
       "             10138       0.011959      0.009056      0.008180      0.014615  \n",
       "             10145       0.011343      0.007313      0.012116      0.013925  \n",
       "...                           ...           ...           ...           ...  \n",
       "2021 2021-12 93304       0.010649      0.008006      0.007048      0.013521  \n",
       "             93373      -0.008803     -0.008924     -0.030353     -0.030865  \n",
       "             93374       0.011274      0.012942      0.008641      0.015326  \n",
       "             93423       0.010649      0.013714      0.013107      0.015131  \n",
       "             93436       0.011802      0.002397      0.007745      0.014447  \n",
       "\n",
       "[61724 rows x 151 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Y_test_preds\n",
    "Y_test_preds.to_csv(r'%s/%s_test_preds.csv'%(model_name, model_name))\n",
    "Y_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c8d1c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tra_loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_ix</th>\n",
       "      <th>l_rate</th>\n",
       "      <th>l1_pen</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>12.977783</td>\n",
       "      <td>12.945484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>12.980109</td>\n",
       "      <td>12.947809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>12.982489</td>\n",
       "      <td>12.950373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>12.983815</td>\n",
       "      <td>12.952406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>12.983659</td>\n",
       "      <td>12.952679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12.989036</td>\n",
       "      <td>12.953050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12.988798</td>\n",
       "      <td>12.954976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12.989268</td>\n",
       "      <td>12.955285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12.991380</td>\n",
       "      <td>12.958274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12.992351</td>\n",
       "      <td>12.958351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>12.980662</td>\n",
       "      <td>12.959072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12.992850</td>\n",
       "      <td>12.959483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12.994186</td>\n",
       "      <td>12.960625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12.994880</td>\n",
       "      <td>12.961189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12.992150</td>\n",
       "      <td>12.961281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12.998906</td>\n",
       "      <td>12.967715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>12.988839</td>\n",
       "      <td>12.968469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <th>0.010</th>\n",
       "      <th>0.00001</th>\n",
       "      <td>12.984001</td>\n",
       "      <td>12.969533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <th>0.010</th>\n",
       "      <th>0.00001</th>\n",
       "      <td>12.985782</td>\n",
       "      <td>12.970388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>12.984147</td>\n",
       "      <td>12.972919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          tra_loss   val_loss\n",
       "model_ix l_rate l1_pen                       \n",
       "115      0.001  0.00005  12.977783  12.945484\n",
       "116      0.001  0.00005  12.980109  12.947809\n",
       "110      0.001  0.00005  12.982489  12.950373\n",
       "117      0.001  0.00005  12.983815  12.952406\n",
       "112      0.001  0.00005  12.983659  12.952679\n",
       "88       0.001  0.00010  12.989036  12.953050\n",
       "85       0.001  0.00010  12.988798  12.954976\n",
       "89       0.001  0.00010  12.989268  12.955285\n",
       "87       0.001  0.00010  12.991380  12.958274\n",
       "84       0.001  0.00010  12.992351  12.958351\n",
       "119      0.001  0.00005  12.980662  12.959072\n",
       "82       0.001  0.00010  12.992850  12.959483\n",
       "86       0.001  0.00010  12.994186  12.960625\n",
       "80       0.001  0.00010  12.994880  12.961189\n",
       "83       0.001  0.00010  12.992150  12.961281\n",
       "81       0.001  0.00010  12.998906  12.967715\n",
       "118      0.001  0.00005  12.988839  12.968469\n",
       "129      0.010  0.00001  12.984001  12.969533\n",
       "123      0.010  0.00001  12.985782  12.970388\n",
       "111      0.001  0.00005  12.984147  12.972919"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Result overview\n",
    "table = pd.DataFrame(results)\n",
    "table = table.groupby(['model_ix', 'l_rate', 'l1_pen']).mean().sort_values('val_loss')\n",
    "table.to_csv(r'%s/%s_results.csv'%(model_name, model_name))\n",
    "\n",
    "np.sqrt(table[['tra_loss', 'val_loss']].head(20)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d455b045",
   "metadata": {},
   "source": [
    "## Model Selection: Maximize SR on LS-Portfolio on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9531a12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'NN3_trad'\n",
    "\n",
    "# Get predictions\n",
    "val = pd.read_csv(r'%s/%s_val_preds.csv'%(model_name, model_name), index_col=['year', 'YM', 'permno'])\n",
    "test = pd.read_csv(r'%s/%s_test_preds.csv'%(model_name, model_name), index_col=['year', 'YM', 'permno'])\n",
    "\n",
    "# Get overview table\n",
    "table = pd.read_csv(r'%s/%s_results.csv'%(model_name, model_name)).sort_values(['model_ix'])\n",
    "\n",
    "# Extract hyperparameters\n",
    "list_l_rate = list(pd.unique(table['l_rate']))\n",
    "list_l1_pen = list(pd.unique(table['l1_pen']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "587bb6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over hyperparameter combinations to get ensemble predictions for each hyperparameter combination\n",
    "val_results = []\n",
    "hyper_comb = 0\n",
    "for l_rate in list_l_rate:\n",
    "    for l1_pen in list_l1_pen:\n",
    "        # Get list of relevant model_ix\n",
    "        list_model_ix = table[(table['l_rate'] == l_rate) & (table['l1_pen'] == l1_pen)]\n",
    "        list_model_ix = list(list_model_ix['model_ix'])\n",
    "        # Get list of column names\n",
    "        list_col_names = []\n",
    "        for ele in list_model_ix:\n",
    "            list_col_names.append('%s_%d'%(model_name, ele))\n",
    "        # Select relevant returns and average predictions\n",
    "        val_ret = val[list_col_names]\n",
    "        val_ret = val_ret.mean(axis=1)\n",
    "        # Append ensemble return prediction to true returns\n",
    "        comb = val[['ret_ex']].copy()\n",
    "        comb['ret_pred'] = val_ret\n",
    "        comb = comb.reset_index()\n",
    "        # Sort the data by predicted returns and divide the data into quintiles\n",
    "        comb['quintile'] = comb.groupby(['YM'])['ret_pred'].transform(lambda x: pd.qcut(x.rank(method='first'), 5, labels=np.arange(1,6)))\n",
    "        # Calculate the mean return for each YM\n",
    "        comb_mean = comb.groupby(['YM', 'quintile']).agg(ret_ex = ('ret_ex', 'mean'))\n",
    "        # Add LS-Strategy\n",
    "        comb_mean = comb_mean[['ret_ex']].unstack().add_prefix('Q')\n",
    "        comb_mean.columns = comb_mean.columns.droplevel(0)\n",
    "        comb_mean.columns.name = None\n",
    "        comb_mean['LS'] = comb_mean['Q5'] - comb_mean['Q1']\n",
    "        # Calculate the average return, standard deviation and Sharpe Ratio (annualized) per Quintile\n",
    "        summary = pd.DataFrame()\n",
    "        summary['mean'] = comb_mean.mean()\n",
    "        summary['std'] = comb_mean.std()\n",
    "        summary['SR'] = summary['mean'] / summary['std'] * np.sqrt(12)\n",
    "        # Append results\n",
    "        val_results.append({\n",
    "            'hyper_comb':hyper_comb,\n",
    "            'l_rate'    :l_rate,\n",
    "            'l1_pen'    :l1_pen,\n",
    "            'SR_Q1'     :summary.loc['Q1','SR'],\n",
    "            'SR_Q5'     :summary.loc['Q5','SR'],\n",
    "            'SR_LS'     :summary.loc['LS','SR'],\n",
    "            'Mean_Q1'   :summary.loc['Q1','mean'],\n",
    "            'Mean_Q5'   :summary.loc['Q5','mean'],\n",
    "            'Mean_LS'   :summary.loc['LS','mean'],\n",
    "        })\n",
    "        hyper_comb += 1\n",
    "        \n",
    "# Save results\n",
    "val_results = pd.DataFrame(val_results)\n",
    "val_results.to_csv(r'results/{}_val.csv'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "578834c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal l_rate: 0.001\n",
      "Optimal l1_pen: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>hyper_comb</th>\n",
       "      <th>SR_Q1</th>\n",
       "      <th>SR_Q5</th>\n",
       "      <th>SR_LS</th>\n",
       "      <th>Mean_Q1</th>\n",
       "      <th>Mean_Q5</th>\n",
       "      <th>Mean_LS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_rate</th>\n",
       "      <th>l1_pen</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00001</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.073488</td>\n",
       "      <td>0.393110</td>\n",
       "      <td>0.603447</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.007038</td>\n",
       "      <td>0.005386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005</th>\n",
       "      <th>0.00001</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.040312</td>\n",
       "      <td>0.415203</td>\n",
       "      <td>0.596897</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.007105</td>\n",
       "      <td>0.006157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.010</th>\n",
       "      <th>0.00100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.162740</td>\n",
       "      <td>0.531752</td>\n",
       "      <td>0.575295</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>0.008005</td>\n",
       "      <td>0.004735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00001</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.047440</td>\n",
       "      <td>0.458545</td>\n",
       "      <td>0.564957</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>0.006422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00050</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164962</td>\n",
       "      <td>0.508890</td>\n",
       "      <td>0.500430</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>0.004936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.128666</td>\n",
       "      <td>0.620777</td>\n",
       "      <td>0.394615</td>\n",
       "      <td>0.003111</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>0.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.137656</td>\n",
       "      <td>0.564931</td>\n",
       "      <td>0.370869</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>0.004927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.337969</td>\n",
       "      <td>0.444874</td>\n",
       "      <td>0.259331</td>\n",
       "      <td>0.005791</td>\n",
       "      <td>0.007593</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.005</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.322487</td>\n",
       "      <td>0.438117</td>\n",
       "      <td>0.117206</td>\n",
       "      <td>0.006256</td>\n",
       "      <td>0.007154</td>\n",
       "      <td>0.000897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00100</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.308877</td>\n",
       "      <td>0.354539</td>\n",
       "      <td>0.029507</td>\n",
       "      <td>0.005797</td>\n",
       "      <td>0.006078</td>\n",
       "      <td>0.000281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <th>0.00010</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.390451</td>\n",
       "      <td>0.266074</td>\n",
       "      <td>-0.110900</td>\n",
       "      <td>0.006106</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>-0.000786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <th>0.00005</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.298208</td>\n",
       "      <td>0.312984</td>\n",
       "      <td>-0.128704</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>-0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.001</th>\n",
       "      <th>0.00050</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.425517</td>\n",
       "      <td>0.361857</td>\n",
       "      <td>-0.243399</td>\n",
       "      <td>0.007345</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>-0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00100</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.426279</td>\n",
       "      <td>0.295371</td>\n",
       "      <td>-0.270335</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>-0.001505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005</th>\n",
       "      <th>0.00050</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.413575</td>\n",
       "      <td>0.294433</td>\n",
       "      <td>-0.290641</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>-0.001694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Unnamed: 0  hyper_comb     SR_Q1     SR_Q5     SR_LS  \\\n",
       "l_rate l1_pen                                                          \n",
       "0.001  0.00001          14          14  0.073488  0.393110  0.603447   \n",
       "0.005  0.00001           9           9  0.040312  0.415203  0.596897   \n",
       "0.010  0.00100           0           0  0.162740  0.531752  0.575295   \n",
       "       0.00001           4           4  0.047440  0.458545  0.564957   \n",
       "       0.00050           1           1  0.164962  0.508890  0.500430   \n",
       "0.001  0.00005          13          13  0.128666  0.620777  0.394615   \n",
       "0.005  0.00005           8           8  0.137656  0.564931  0.370869   \n",
       "0.010  0.00010           2           2  0.337969  0.444874  0.259331   \n",
       "0.005  0.00010           7           7  0.322487  0.438117  0.117206   \n",
       "       0.00100           5           5  0.308877  0.354539  0.029507   \n",
       "0.001  0.00010          12          12  0.390451  0.266074 -0.110900   \n",
       "0.010  0.00005           3           3  0.298208  0.312984 -0.128704   \n",
       "0.001  0.00050          11          11  0.425517  0.361857 -0.243399   \n",
       "       0.00100          10          10  0.426279  0.295371 -0.270335   \n",
       "0.005  0.00050           6           6  0.413575  0.294433 -0.290641   \n",
       "\n",
       "                 Mean_Q1   Mean_Q5   Mean_LS  \n",
       "l_rate l1_pen                                 \n",
       "0.001  0.00001  0.001652  0.007038  0.005386  \n",
       "0.005  0.00001  0.000948  0.007105  0.006157  \n",
       "0.010  0.00100  0.003271  0.008005  0.004735  \n",
       "       0.00001  0.001157  0.007579  0.006422  \n",
       "       0.00050  0.003308  0.008244  0.004936  \n",
       "0.001  0.00005  0.003111  0.008611  0.005500  \n",
       "0.005  0.00005  0.003332  0.008258  0.004927  \n",
       "0.010  0.00010  0.005791  0.007593  0.001802  \n",
       "0.005  0.00010  0.006256  0.007154  0.000897  \n",
       "       0.00100  0.005797  0.006078  0.000281  \n",
       "0.001  0.00010  0.006106  0.005320 -0.000786  \n",
       "0.010  0.00005  0.006591  0.005092 -0.001500  \n",
       "0.001  0.00050  0.007345  0.006271 -0.001073  \n",
       "       0.00100  0.006974  0.005469 -0.001505  \n",
       "0.005  0.00050  0.007070  0.005376 -0.001694  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select best hyperparemeters (max. SR_LS)\n",
    "val_results = val = pd.read_csv(r'results/{}_val.csv'.format(model_name))\n",
    "val_results = val_results.set_index(['l_rate', 'l1_pen']).sort_values(['SR_LS'], ascending=False)\n",
    "l_rate_opt, l1_pen_opt = tuple([x for x in val_results.iloc[0].name[0:]])\n",
    "print('Optimal l_rate:', l_rate_opt)\n",
    "print('Optimal l1_pen:', l1_pen_opt)\n",
    "val_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1f3b09",
   "metadata": {},
   "source": [
    "## Out-of-Sample: Get Predictions of model with best hyperparameter combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3f495b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of model_ix's with best hyperparameter combinations and make ensemble predictions\n",
    "list_model_ix = table[(table['l_rate'] == l_rate_opt) & (table['l1_pen'] == l1_pen_opt)]\n",
    "list_model_ix = list(list_model_ix['model_ix'])\n",
    "\n",
    "# Get list of column names\n",
    "list_col_names = []\n",
    "for ele in list_model_ix:\n",
    "    list_col_names.append('%s_%d'%(model_name, ele))\n",
    "    \n",
    "# Select relevant returns and average predictions\n",
    "test_ret = test[list_col_names].copy()\n",
    "test_ret['y_pred'] = test_ret.mean(axis=1)\n",
    "\n",
    "# Save predictions\n",
    "test_ret = test_ret.reset_index()\n",
    "test_ret = test_ret[['YM', 'permno', 'y_pred']]\n",
    "test_ret.to_csv(r'results/{}_predictions.csv'.format(model_name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
